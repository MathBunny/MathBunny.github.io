{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome\n\n\nWelcome to the Karnaugh Map Simplification Software documentation site. The purpose of this website is to provide documentation to both developers and to users.\n\n\nHistory and Objective\n\n\nThe purpose of this software is to provide a collection of tools for engineers to simplify logical expressions and to visualize the results in a Karnaugh Map. There are two versions of the software. The first version, which was started in 2015 used Java Swing and supported up to four variable visual expression simplification. In the summer of 2017, a new version started development which is being made in JavaFX. \n\n\nFuture Goals\n\n\nThe ultimate goal for this project is to become the standard industry tool in working with boolean algebra expressions. This includes simplification of large expressions, and working on converting expressions between different forms.\n\n\nDownload Links\n\n\n\n\n\n\n\n\nDescription\n\n\nJava Required\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nLatest stable build\n\n\nJRE 1.6\n\n\nDownload\n\n\n\n\n\n\nLatest stable source\n\n\nJDK 1.7\n\n\nDownload\n\n\n\n\n\n\nDevelopment source\n\n\nJDK 1.8\n\n\nGitHub\n\n\n\n\n\n\n\n\nYouTube Tutorials \n Demos\n\n\n\n\n\n\n\n\nTutorial Topic\n\n\nYouTube Link\n\n\n\n\n\n\n\n\n\n\nGeneral Software Demonstration\n\n\nView video\n\n\n\n\n\n\n\n\nJavaDoc Documentation\n\n\n\n\n\n\n\n\nDescription\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nStable build documentation\n\n\nView JavaDoc", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome", 
            "text": "Welcome to the Karnaugh Map Simplification Software documentation site. The purpose of this website is to provide documentation to both developers and to users.", 
            "title": "Welcome"
        }, 
        {
            "location": "/#history-and-objective", 
            "text": "The purpose of this software is to provide a collection of tools for engineers to simplify logical expressions and to visualize the results in a Karnaugh Map. There are two versions of the software. The first version, which was started in 2015 used Java Swing and supported up to four variable visual expression simplification. In the summer of 2017, a new version started development which is being made in JavaFX.", 
            "title": "History and Objective"
        }, 
        {
            "location": "/#future-goals", 
            "text": "The ultimate goal for this project is to become the standard industry tool in working with boolean algebra expressions. This includes simplification of large expressions, and working on converting expressions between different forms.", 
            "title": "Future Goals"
        }, 
        {
            "location": "/#download-links", 
            "text": "Description  Java Required  Link      Latest stable build  JRE 1.6  Download    Latest stable source  JDK 1.7  Download    Development source  JDK 1.8  GitHub", 
            "title": "Download Links"
        }, 
        {
            "location": "/#youtube-tutorials-demos", 
            "text": "Tutorial Topic  YouTube Link      General Software Demonstration  View video", 
            "title": "YouTube Tutorials &amp; Demos"
        }, 
        {
            "location": "/#javadoc-documentation", 
            "text": "Description  Link      Stable build documentation  View JavaDoc", 
            "title": "JavaDoc Documentation"
        }, 
        {
            "location": "/Boolean Algebra/", 
            "text": "Boolean Algebra and Operators\n\n\nBoolean algebra is a branch of algebra where the values of variables can only be \ntrue\n or \nfalse\n (often denoted by \n1\n and \n0\n respectfully). We use boolean algebra in circuits, general two-valued logic (such as in mathematics), and boolean operations.\n\n\nThere are multiple operations in boolean algebra, but the ones we will focus on are \nAND\n and \nOR\n. We denote \nAND\n through multiplication (ex: \nAB\n) and we denote \nOR\n through addition (ex: \nA+B\n). These operations follow the commutative property, meaning that the order in which we place the operands does not matter. We also have \nNOT\n, denoted by \n'\n operator, which flips the sign, for example \nA'\n.\n\n\nTruth Tables\n\n\nWhenever we have a boolean expression, we can express it as a function. Similar to \nF(x)\n we can express a two variable function: \nF(AB)\n, where we can say our domain is \n{A,B}\n. Since our input values can only be \ntrue\n or \nfalse\n, we can create a truth table that will show all possible cases with their inputs to the function and the result. Let's take a look at a simple two variable expression, and see how the logic gates \nAND\n and \nOR\n work. \n\n\nFor example, let's take the equation \nF(AB) = AB\n and generate the truth table: \n\n\n\n\n\n\n\n\nF(AB)\n\n\nA\n\n\nB\n\n\n\n\n\n\n\n\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n0\n\n\n0\n\n\n1\n\n\n\n\n\n\n0\n\n\n1\n\n\n0\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n\n\n\n\n\n\nWe can also take the equation \nF(AB) = A+B\n and generate the truth table:\n\n\n\n\n\n\n\n\nF(A+B)\n\n\nA\n\n\nB\n\n\n\n\n\n\n\n\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n1\n\n\n0\n\n\n1\n\n\n\n\n\n\n1\n\n\n1\n\n\n0\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n\n\n\n\n\n\nTruth tables are important because we can easily evaluate for the behavior of a function. For user input, it is easier to input truth tables because we can specify cases such as \nDon't Cares\n, which will be discussed later on. \n\n\nSum of Product Expressions (SOP)\n\n\nLet's consider a more complicated expression \nF(ABCD)= AB'C+BD+CD+D\n and generate its truth table:\n\n\n\n\n\n\n\n\nF(AB'C+BD+CD+D)\n\n\nA\n\n\nB\n\n\nC\n\n\nD\n\n\n\n\n\n\n\n\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n1\n\n\n\n\n\n\n0\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n\n\n\n\n1\n\n\n0\n\n\n0\n\n\n1\n\n\n1\n\n\n\n\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\n\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n\n\n\n\n0\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n\n\n\n\n1\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n\n\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n1\n\n\n\n\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n\n\n\n\n1\n\n\n1\n\n\n0\n\n\n1\n\n\n1\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n0\n\n\n1\n\n\n\n\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n0\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n1\n\n\n1\n\n\n\n\n\n\n\n\nThis example was definately more involved than the previous expressions. An interesting observation is that we are doing a sum of product evaluation, that is, \nAB'C+BD+CD+D\n is a sum of products. The significance of a sum of product is that when we are doing \n+\n we are in fact invoking the \nOR\n operator. \n\n\nMoreover, the \nOR\n operator returns \ntrue\n so long as any one of its arguements returns \ntrue\n. Therefore, if \nany\n of the terms in the sum of product (SOP) expressions is \ntrue\n, then we know that the final expression is \ntrue\n for certain. \n\n\nExample Algebraic Simplification\n\n\nLet's simplify our expression from the previous truth table example. We can apply ordinary algebra tricks such as factoring. Remember that the \n+\n operator invokes the \nOR\n gate, and that \ntrue or x\n always returns \ntrue\n regardless of \nx\n (as shown in our first truth table).\n\n\nAB'C+BD+CD+D // Initial expression\nAB'C+BD+D(C+1) // Factor out a D\nAB'C+BD+D // Since (C+1) is always true, as C OR true is always true\nAB'C+D(B+1) // Factor out a D again\nAB'C+D // Since (B+1) is always true, as B OR true is always true\n=AB'C+D // Final expression\n\n\n\n\nAs an exercise to the reader, complete the truth table to show that they are logically equivalent. \n\n\nUndefined Input \n Don't Cares\n\n\nThe definition of a \"Don't care\" is a combination of input values that is not known, and could be either \n0\n or \n1\n. For the purposes of variable simplification, we would choose the greedy approach of picking between {\n0\n, \n1\n} such that the simplified expression has less terms.\n\n\nLet's consider the following truth-table:\n\n\n\n\n\n\n\n\nF(AB)\n\n\nA\n\n\nB\n\n\n\n\n\n\n\n\n\n\n1\n\n\n0\n\n\n0\n\n\n\n\n\n\n1\n\n\n0\n\n\n1\n\n\n\n\n\n\n?\n\n\n1\n\n\n0\n\n\n\n\n\n\n1\n\n\n1\n\n\n1\n\n\n\n\n\n\n\n\nWe observe that we have a \nDon't care\n. Let's observe the differences in cases for \nF(1,0)\n:\n\n\nCase #1: F(1, 0) = 0\n=\n F(AB) = A'B' + A'B + AB\n\nCase #2: F(1, 0) = 1\n=\n F(AB) = A'B' + A'B + AB' + AB\n\nSimplifying the cases...\nF(AB) = A'B' + A'B + AB\n      = A'(B' + B) + AB\n      = A' + AB\nF(AB) = A'B' + A'B + AB' + AB\n      = A'(B' + B) + A (B' + B)\n      = A' + A\n      = 1\n\n\n\n\nWe can clearly see, if we set \nF(1, 0) = 1\n, we get a true value for any input. Therefore, for the purposes of variable simplification, we can simply let \nF(1, 0) = 1\n thus implying \nF(AB) = 1\n.\n\n\nAdditional Logic Gates\n\n\nSo far we covered the \nNOT\n unary operator, in addition to the binary operators \nOR\n and \nAND\n.", 
            "title": "Boolean Algebra"
        }, 
        {
            "location": "/Boolean Algebra/#boolean-algebra-and-operators", 
            "text": "Boolean algebra is a branch of algebra where the values of variables can only be  true  or  false  (often denoted by  1  and  0  respectfully). We use boolean algebra in circuits, general two-valued logic (such as in mathematics), and boolean operations.  There are multiple operations in boolean algebra, but the ones we will focus on are  AND  and  OR . We denote  AND  through multiplication (ex:  AB ) and we denote  OR  through addition (ex:  A+B ). These operations follow the commutative property, meaning that the order in which we place the operands does not matter. We also have  NOT , denoted by  '  operator, which flips the sign, for example  A' .", 
            "title": "Boolean Algebra and Operators"
        }, 
        {
            "location": "/Boolean Algebra/#truth-tables", 
            "text": "Whenever we have a boolean expression, we can express it as a function. Similar to  F(x)  we can express a two variable function:  F(AB) , where we can say our domain is  {A,B} . Since our input values can only be  true  or  false , we can create a truth table that will show all possible cases with their inputs to the function and the result. Let's take a look at a simple two variable expression, and see how the logic gates  AND  and  OR  work.   For example, let's take the equation  F(AB) = AB  and generate the truth table:      F(AB)  A  B      0  0  0    0  0  1    0  1  0    1  1  1     We can also take the equation  F(AB) = A+B  and generate the truth table:     F(A+B)  A  B      0  0  0    1  0  1    1  1  0    1  1  1     Truth tables are important because we can easily evaluate for the behavior of a function. For user input, it is easier to input truth tables because we can specify cases such as  Don't Cares , which will be discussed later on.", 
            "title": "Truth Tables"
        }, 
        {
            "location": "/Boolean Algebra/#sum-of-product-expressions-sop", 
            "text": "Let's consider a more complicated expression  F(ABCD)= AB'C+BD+CD+D  and generate its truth table:     F(AB'C+BD+CD+D)  A  B  C  D      0  0  0  0  0    1  0  0  0  1    0  0  0  1  0    1  0  0  1  1    0  0  1  0  0    1  0  1  0  1    0  0  1  1  0    1  0  1  1  1    0  1  0  0  0    1  1  0  0  1    0  1  0  1  0    1  1  0  1  1    1  1  1  0  0    1  1  1  0  1    0  1  1  1  0    1  1  1  1  1     This example was definately more involved than the previous expressions. An interesting observation is that we are doing a sum of product evaluation, that is,  AB'C+BD+CD+D  is a sum of products. The significance of a sum of product is that when we are doing  +  we are in fact invoking the  OR  operator.   Moreover, the  OR  operator returns  true  so long as any one of its arguements returns  true . Therefore, if  any  of the terms in the sum of product (SOP) expressions is  true , then we know that the final expression is  true  for certain.", 
            "title": "Sum of Product Expressions (SOP)"
        }, 
        {
            "location": "/Boolean Algebra/#example-algebraic-simplification", 
            "text": "Let's simplify our expression from the previous truth table example. We can apply ordinary algebra tricks such as factoring. Remember that the  +  operator invokes the  OR  gate, and that  true or x  always returns  true  regardless of  x  (as shown in our first truth table).  AB'C+BD+CD+D // Initial expression\nAB'C+BD+D(C+1) // Factor out a D\nAB'C+BD+D // Since (C+1) is always true, as C OR true is always true\nAB'C+D(B+1) // Factor out a D again\nAB'C+D // Since (B+1) is always true, as B OR true is always true\n=AB'C+D // Final expression  As an exercise to the reader, complete the truth table to show that they are logically equivalent.", 
            "title": "Example Algebraic Simplification"
        }, 
        {
            "location": "/Boolean Algebra/#undefined-input-dont-cares", 
            "text": "The definition of a \"Don't care\" is a combination of input values that is not known, and could be either  0  or  1 . For the purposes of variable simplification, we would choose the greedy approach of picking between { 0 ,  1 } such that the simplified expression has less terms.  Let's consider the following truth-table:     F(AB)  A  B      1  0  0    1  0  1    ?  1  0    1  1  1     We observe that we have a  Don't care . Let's observe the differences in cases for  F(1,0) :  Case #1: F(1, 0) = 0\n=  F(AB) = A'B' + A'B + AB\n\nCase #2: F(1, 0) = 1\n=  F(AB) = A'B' + A'B + AB' + AB\n\nSimplifying the cases...\nF(AB) = A'B' + A'B + AB\n      = A'(B' + B) + AB\n      = A' + AB\nF(AB) = A'B' + A'B + AB' + AB\n      = A'(B' + B) + A (B' + B)\n      = A' + A\n      = 1  We can clearly see, if we set  F(1, 0) = 1 , we get a true value for any input. Therefore, for the purposes of variable simplification, we can simply let  F(1, 0) = 1  thus implying  F(AB) = 1 .", 
            "title": "Undefined Input &amp; Don't Cares"
        }, 
        {
            "location": "/Boolean Algebra/#additional-logic-gates", 
            "text": "So far we covered the  NOT  unary operator, in addition to the binary operators  OR  and  AND .", 
            "title": "Additional Logic Gates"
        }, 
        {
            "location": "/Karnaugh Maps/", 
            "text": "Introduction\n\n\nKarnaugh Maps are a way to visually display a boolean expression onto a 2D grid. We take the variables and bind them to an axis, and then enumerate through the possible combinations of input values that could occur for all those variables bounded to an axis (either horizontally or vertically).\n\n\nFor example, we can display the following 2 variable Karnaugh Map:\n\n\n\n\nWe have bounded to the vertical axis, the variable \nA\n, and we enumerate through the possible values for \nA\n (being \n{0, 1}\n). Similarily, we perform a similar operation for the \nB\n variable. Since we are using a 2 variable expression, we can bound one variable to each axis and the visualization works fine in a \n2x2\n matrix.\n\n\nLet's instead look at a more involved example with 4 variables:\n\n\n\n\nWe have now bounded the \nA\n and \nB\n variables to the vertical axis, while we bounded the \nC\n and \nD\n variables to the horizontal axis. We now enumarate through different combinations of the bounded variables for each axis in \nreflected binary code order\n (more on this in the following section). Lastly, we indicate on the matrix each true value by augmenting a \n1\n value.\n\n\nEnumeration and Gray Codes\n\n\nWhen enumerating through the variable input combinations for the binded axis, we take advantage of \nreflected binary code order\n, otherwise known as gray codes. If we observe carefully, we can notice that from one combination to another, we only vary by one bit. That is:\n\n\n... 00 01 11 10 00 01 11 10 00 ...\n    ^   ^ ^   ^ ^   ^ ^   ^ ^\n\n\n\n\nThus, we get this wrapping that allows us to switch by only one bit. This provides us the core for how Karnaugh Maps work.\n\n\nSimple Groupings\n\n\nThe main idea for how Karnaugh Maps can be used to simplify expressions is to group pairs of \n1\n values that are adjacent, and exploit the fact that each one has only a bit difference from another. \n\n\n\n\nFor the purpose of this example, let \nF(ABCD) = CELL\n. We start with the expression \nF(0000) = 1\n and \nF(0001) = 1\n. However, notice that \nregardless\n of the value of the last bit, we still get \n1\n. Hence, let's take a look at the SOP expressions:\n\n\nF(ABCD) = A'B'C'D' + A'B'C'D\nF(0000) = 1\nF(0001) = 1\n\nSince the last bit is the same, we can ignore the D value, thus:\nF(ABCD) = A'B'C'\n\nWe can confirm by simplifying algebraically:\nF(ABCD) = A'B'C'D' + A'B'C'D\n        = A'B'C'(D' + D)\n        = A'B'C'\nTherefore, the simplification is true.\n\n\n\n\nWe can then extend this rule to work for rectangles and more!\n\n\nTwo Dimension Groupings\n\n\nExtending the idea of isolating changing bits that retain a consistent value, we can then generalize this to work in a higher dimension. Consider the following example:\n\n\n\n\nLetting \nF(ABCD) = CELL\n:\n\n\nF(0000) = 1\nF(0001) = 1\nF(0100) = 1\nF(0101) = 1\n\n\n\n\nObserve that the bits do not change by one for all pairs of numbers, for example \n{0000, 0101}\n differ by two bits. However, we can take advantage of the fact that for any bit change horizontally or vertically, it's irrelvant what that bit is. More concretely, take a look at the following example.\n\n\n0000 0001\n0100 0101\n\n=\n A'B'C'D' + A'B'C'D + A'BC'D' + A'BC'D\nRegardless of the B variable, we still get true for all products in the SOP expression.\nThis is bounded vertically:\n=\n A'C'D' + A'C'D + A'C'D' + A'C'D\nRegardless of the D variable, we still get true for all products in the SOP expression.\nThis is bounded horizontally:\n=\n A'C' + A'C' + A'C' + A'C'\n=\n A'C' (1 + 1 + 1 + 1)\n=\n A'C' (1)\n=\n A'C'\n\n\n\n\nSince the differences in bits needs to generalize throughout a binding of an axis, you can only have a binding of size \n2^n\n for a given axis. For example, \n1x1, 1x2, 1x4, 2x2, 2x4, 4x4\n. \n\n\nDisjoint Groupings\n\n\nConsider the following example:\n\n\n\nThe algorithm follows precisely as it did before, except that now the two groups are joined in the SOP expression. Letting \nF(ABCD) = CELL\n:\n\n\nF(0000) = 1\nF(0001) = 1\nF(1111) = 1\nF(1011) = 1\n\n\n\n\nThis yields the following:\n\n\nA'B'C'D' + A'B'C'D + ABCD + AB'CD\nBreaking down the expression:\n(A'B'C'D' + A'B'C'D) + (ABCD + AB'CD)\n=\n (A'B'C'(D + D')) + (ACD(B + B'))\n=\n (A'B'C') + (ACD)\n=\n A'B'C' + ACD\n\n\n\n\nClearly this is the exact same process as before, but iterated throughout all the disjoint sets.\n\n\nOverlapping Groupings\n\n\nOverlapping groupings become more complex, because there exist ambigious cases and sometimes what may appear to be a locally optimal solutuion is not a globally optimal solution.\n\n\nThe general technique for evaluating for overlapping groups follows a greedy algorithm. Define an unvisited cell as a cell that has a value of \n1\n however it is currently not matched with a grouping yet. \n\n\nIterate through all the cells, and once you find a cell with \n1\n, if it is unvisited then find the largest possible square or rectangle such that each side length is a power of 2, where all the cells are \n1\n in its enclosed area. If there is a tie for size (ie, \n1x4\n vs \n2x2\n), assign the one that is a square (this is by convention). \n\n\nRepeat this process for all remaining unvisited cells. Note: You can overlap the groupings with already visited nodes, but you never instantiate a new grouping unless the current node is unvisited.\n\n\n\n\nIn this example, at \nF(0000)\n, we can create a grouping of size 2 (because 2 is the largest possible grouping, 3 is not a power of 2). We then iterate through to \nF(0001)\n, however \nF(0001)\n was already resolved to a grouping. For the latest active cell, \nF(0011)\n is not resolved to a grouping thus it's unvisited. The largest possible grouping is also of size 2, thus we create another group.\n\n\nTo resolve the groupings into an SOP expression, we iterate through the groups and identify changing bits:\n\n\nGroup #1 =\n F(ABCD) = [0000, 0001]\nGroup #2 =\n F(ABCD) = [0001, 0011]\n\nFor Group #1:\n0000 0001\n   ^    ^\nF(ABCD) = A'B'C'D' + A'B'C'D\n=\n A'B'C'(D + D')\n=\n A'B'C'\n\nFor Group #2:\n0001 0011\n  ^    ^\nF(ABCD) = A'B'C'D + A'B'CD\n=\n A'B'D(C' + C)\n=\n A'B'D\n\nNow we add the two results:\nF(ABCD) = A'B'C' + A'B'D\n=\n F(ABCD) = A'B'D + A'B'C' (by commutative property)\n\n\n\n\nMinimizing Group Count\n\n\nThe following example will ilustrate how the greedy approach may occasionally produce too many groups. Consider the following example:\n\n\n\n\nThis grouping state is optimal. However, consider adding a \n1\n to \nF(1111)\n.\n\n\n\n\nFollowing the previous algorithm, iterating top-bottom and left-right, when getting to \nF(0110)\n, the algorithm can choose to make the largest grouping. However, there are two possible groupings:\n\n\nCandidate #1:\nF(ABCD) = [0011, 0010, 0111, 0110]\n\nCandidate #2:\nF(ABCD) = [0111, 0110, 1111, 1110]\n\n\n\n\nBoth groupings have the same size, and are the same dimension. However, upon reaching \nF(1110)\n, another grouping needs to be instantiated, in which case if the first candidate grouping was created then we made a group that was not neccessary increasing the size of our SOP expression. \n\n\nThis illustrates the idea that this is a greedy algorithm, and does not always return the most simplified SOP expression. In later sections, algorithms illustrating a globally optimal algorithm will be discussed.", 
            "title": "Karnaugh Maps"
        }, 
        {
            "location": "/Karnaugh Maps/#introduction", 
            "text": "Karnaugh Maps are a way to visually display a boolean expression onto a 2D grid. We take the variables and bind them to an axis, and then enumerate through the possible combinations of input values that could occur for all those variables bounded to an axis (either horizontally or vertically).  For example, we can display the following 2 variable Karnaugh Map:   We have bounded to the vertical axis, the variable  A , and we enumerate through the possible values for  A  (being  {0, 1} ). Similarily, we perform a similar operation for the  B  variable. Since we are using a 2 variable expression, we can bound one variable to each axis and the visualization works fine in a  2x2  matrix.  Let's instead look at a more involved example with 4 variables:   We have now bounded the  A  and  B  variables to the vertical axis, while we bounded the  C  and  D  variables to the horizontal axis. We now enumarate through different combinations of the bounded variables for each axis in  reflected binary code order  (more on this in the following section). Lastly, we indicate on the matrix each true value by augmenting a  1  value.", 
            "title": "Introduction"
        }, 
        {
            "location": "/Karnaugh Maps/#enumeration-and-gray-codes", 
            "text": "When enumerating through the variable input combinations for the binded axis, we take advantage of  reflected binary code order , otherwise known as gray codes. If we observe carefully, we can notice that from one combination to another, we only vary by one bit. That is:  ... 00 01 11 10 00 01 11 10 00 ...\n    ^   ^ ^   ^ ^   ^ ^   ^ ^  Thus, we get this wrapping that allows us to switch by only one bit. This provides us the core for how Karnaugh Maps work.", 
            "title": "Enumeration and Gray Codes"
        }, 
        {
            "location": "/Karnaugh Maps/#simple-groupings", 
            "text": "The main idea for how Karnaugh Maps can be used to simplify expressions is to group pairs of  1  values that are adjacent, and exploit the fact that each one has only a bit difference from another.    For the purpose of this example, let  F(ABCD) = CELL . We start with the expression  F(0000) = 1  and  F(0001) = 1 . However, notice that  regardless  of the value of the last bit, we still get  1 . Hence, let's take a look at the SOP expressions:  F(ABCD) = A'B'C'D' + A'B'C'D\nF(0000) = 1\nF(0001) = 1\n\nSince the last bit is the same, we can ignore the D value, thus:\nF(ABCD) = A'B'C'\n\nWe can confirm by simplifying algebraically:\nF(ABCD) = A'B'C'D' + A'B'C'D\n        = A'B'C'(D' + D)\n        = A'B'C'\nTherefore, the simplification is true.  We can then extend this rule to work for rectangles and more!", 
            "title": "Simple Groupings"
        }, 
        {
            "location": "/Karnaugh Maps/#two-dimension-groupings", 
            "text": "Extending the idea of isolating changing bits that retain a consistent value, we can then generalize this to work in a higher dimension. Consider the following example:   Letting  F(ABCD) = CELL :  F(0000) = 1\nF(0001) = 1\nF(0100) = 1\nF(0101) = 1  Observe that the bits do not change by one for all pairs of numbers, for example  {0000, 0101}  differ by two bits. However, we can take advantage of the fact that for any bit change horizontally or vertically, it's irrelvant what that bit is. More concretely, take a look at the following example.  0000 0001\n0100 0101\n\n=  A'B'C'D' + A'B'C'D + A'BC'D' + A'BC'D\nRegardless of the B variable, we still get true for all products in the SOP expression.\nThis is bounded vertically:\n=  A'C'D' + A'C'D + A'C'D' + A'C'D\nRegardless of the D variable, we still get true for all products in the SOP expression.\nThis is bounded horizontally:\n=  A'C' + A'C' + A'C' + A'C'\n=  A'C' (1 + 1 + 1 + 1)\n=  A'C' (1)\n=  A'C'  Since the differences in bits needs to generalize throughout a binding of an axis, you can only have a binding of size  2^n  for a given axis. For example,  1x1, 1x2, 1x4, 2x2, 2x4, 4x4 .", 
            "title": "Two Dimension Groupings"
        }, 
        {
            "location": "/Karnaugh Maps/#disjoint-groupings", 
            "text": "Consider the following example:  The algorithm follows precisely as it did before, except that now the two groups are joined in the SOP expression. Letting  F(ABCD) = CELL :  F(0000) = 1\nF(0001) = 1\nF(1111) = 1\nF(1011) = 1  This yields the following:  A'B'C'D' + A'B'C'D + ABCD + AB'CD\nBreaking down the expression:\n(A'B'C'D' + A'B'C'D) + (ABCD + AB'CD)\n=  (A'B'C'(D + D')) + (ACD(B + B'))\n=  (A'B'C') + (ACD)\n=  A'B'C' + ACD  Clearly this is the exact same process as before, but iterated throughout all the disjoint sets.", 
            "title": "Disjoint Groupings"
        }, 
        {
            "location": "/Karnaugh Maps/#overlapping-groupings", 
            "text": "Overlapping groupings become more complex, because there exist ambigious cases and sometimes what may appear to be a locally optimal solutuion is not a globally optimal solution.  The general technique for evaluating for overlapping groups follows a greedy algorithm. Define an unvisited cell as a cell that has a value of  1  however it is currently not matched with a grouping yet.   Iterate through all the cells, and once you find a cell with  1 , if it is unvisited then find the largest possible square or rectangle such that each side length is a power of 2, where all the cells are  1  in its enclosed area. If there is a tie for size (ie,  1x4  vs  2x2 ), assign the one that is a square (this is by convention).   Repeat this process for all remaining unvisited cells. Note: You can overlap the groupings with already visited nodes, but you never instantiate a new grouping unless the current node is unvisited.   In this example, at  F(0000) , we can create a grouping of size 2 (because 2 is the largest possible grouping, 3 is not a power of 2). We then iterate through to  F(0001) , however  F(0001)  was already resolved to a grouping. For the latest active cell,  F(0011)  is not resolved to a grouping thus it's unvisited. The largest possible grouping is also of size 2, thus we create another group.  To resolve the groupings into an SOP expression, we iterate through the groups and identify changing bits:  Group #1 =  F(ABCD) = [0000, 0001]\nGroup #2 =  F(ABCD) = [0001, 0011]\n\nFor Group #1:\n0000 0001\n   ^    ^\nF(ABCD) = A'B'C'D' + A'B'C'D\n=  A'B'C'(D + D')\n=  A'B'C'\n\nFor Group #2:\n0001 0011\n  ^    ^\nF(ABCD) = A'B'C'D + A'B'CD\n=  A'B'D(C' + C)\n=  A'B'D\n\nNow we add the two results:\nF(ABCD) = A'B'C' + A'B'D\n=  F(ABCD) = A'B'D + A'B'C' (by commutative property)", 
            "title": "Overlapping Groupings"
        }, 
        {
            "location": "/Karnaugh Maps/#minimizing-group-count", 
            "text": "The following example will ilustrate how the greedy approach may occasionally produce too many groups. Consider the following example:   This grouping state is optimal. However, consider adding a  1  to  F(1111) .   Following the previous algorithm, iterating top-bottom and left-right, when getting to  F(0110) , the algorithm can choose to make the largest grouping. However, there are two possible groupings:  Candidate #1:\nF(ABCD) = [0011, 0010, 0111, 0110]\n\nCandidate #2:\nF(ABCD) = [0111, 0110, 1111, 1110]  Both groupings have the same size, and are the same dimension. However, upon reaching  F(1110) , another grouping needs to be instantiated, in which case if the first candidate grouping was created then we made a group that was not neccessary increasing the size of our SOP expression.   This illustrates the idea that this is a greedy algorithm, and does not always return the most simplified SOP expression. In later sections, algorithms illustrating a globally optimal algorithm will be discussed.", 
            "title": "Minimizing Group Count"
        }, 
        {
            "location": "/Simplification Examples/", 
            "text": "Simplification Examples\n\n\nMore examples coming soon.", 
            "title": "Simplification Examples"
        }, 
        {
            "location": "/Simplification Examples/#simplification-examples", 
            "text": "More examples coming soon.", 
            "title": "Simplification Examples"
        }
    ]
}