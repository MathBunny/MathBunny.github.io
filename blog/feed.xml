<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="http://horatiulazu.ca/blog/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.3.1">Jekyll</generator><link href="http://horatiulazu.ca/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="http://horatiulazu.ca/blog/" rel="alternate" type="text/html" /><updated>2020-10-11T23:34:06-04:00</updated><id>http://horatiulazu.ca/blog//</id><title type="html">Horatiu’s Blog</title><subtitle>My blog, discussing topics from university life.
</subtitle><entry><title type="html">RTC (Real-Time Communication) at scale</title><link href="http://horatiulazu.ca/blog/coop/2020/05/02/rt-calling.html" rel="alternate" type="text/html" title="RTC (Real-Time Communication) at scale" /><published>2020-05-02T19:49:29-04:00</published><updated>2020-05-02T19:49:29-04:00</updated><id>http://horatiulazu.ca/blog/coop/2020/05/02/rt-calling</id><content type="html" xml:base="http://horatiulazu.ca/blog/coop/2020/05/02/rt-calling.html">&lt;p&gt;I recently did an internship at Facebook where I was part of the RTC (Real-Time Communications) org, responsible for the products and infrastructure powering voice/video calling across Facebook’s family of apps (such as Messenger and Instagram). My team was responsible for the P2P and multiway calling protocols, including lower-level services written in C++ and platform integrating with partner teams in PHP.&lt;/p&gt;

&lt;p&gt;This post will dedicate itself to discussing some of the protocols that go into audio and video calling.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;It is not related to Facebook itself in any way.&lt;/strong&gt;  &lt;a href=&quot;/blog/assets/blog-report.pdf&quot;&gt;You can view the PDF version of this post here. &lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;#summary&quot;&gt;Executive Summary&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#analysis&quot;&gt;Analysis&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;2.1 &lt;a href=&quot;#overview&quot;&gt;Overview of Signaling and Media Streaming&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.2 &lt;a href=&quot;#history&quot;&gt;History of Signaling and Media Streaming&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.3 &lt;a href=&quot;#h323&quot;&gt;ITU-T H.323 Protocols&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.4 &lt;a href=&quot;#sip&quot;&gt;Session Initiation Protocol (SIP)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.5 &lt;a href=&quot;#signal&quot;&gt;Signal Protocol (formerly TextSecure Protocol)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.6 &lt;a href=&quot;#webrtc&quot;&gt;WebRTC Framework&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.7 &lt;a href=&quot;#rtsp&quot;&gt;Real-Time Streaming Protocol (RTSP)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.8 &lt;a href=&quot;#rtcp&quot;&gt;Real-Time Control Protocol (RTSP)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.9 &lt;a href=&quot;#rtp&quot;&gt;Real-Time Transport Protocol (RTP)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.10 &lt;a href=&quot;#audiostreaming&quot;&gt;Audio Streaming Codecs&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.11 &lt;a href=&quot;#videostreaming&quot;&gt;Video Streaming Codecs&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.12 &lt;a href=&quot;#dash&quot;&gt;Dynamic Adaptive Streaming over HTTP (DASH)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.13 &lt;a href=&quot;#multiway&quot;&gt;Multiway Calling Architectures&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#casestudies&quot;&gt;Case Studies&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;3.1 &lt;a href=&quot;#skype&quot;&gt;Skype’s P2P Signaling Protocol (2003)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;4.1 &lt;a href=&quot;#result&quot;&gt;Resulting architecture of RTC systems&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;executive-summary&quot;&gt;Executive Summary&lt;/h3&gt;

&lt;p&gt;This post discusses and analyzes different protocols and technologies used in real-time communication systems by social media platforms. Real-time communication typically involves both a signaling and media stack. During signaling, actions are performed, such as ringing and hanging up, which often need to be relayed to users in an efficient manner. Similarly, media involves the encoding, relay and encryption of a stream of data, which includes audio and/or video. This post primarily focuses on a high-level overview of the different stacks, along with open-source protocols defined for use in this context. In addition, this post discusses different algorithms that are applied for media streaming, in the context of codecs and the perspective of performance.&lt;/p&gt;

&lt;p&gt;The objective of this post it to raise familiarity with the challenges associated with real-time communications, and how different companies tackled problems related to it. In particular, this post focuses on the signaling and media streaming aspects, and not on underlying infrastructure details such as ensuring durability or reliability of hardware.&lt;/p&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;The objective of real-time communication in the context of social media is to connect people from different avenues of the world together in a lifelike fashion. By allowing peer-to-peer or multiway communication through audio and/or video, users can connect in a personable way despite being geographically disperced. Billions of calls are performed everyday over the internet, including those from popular sites such as WhatsApp which support over 1 billion daily users (Mansoor Iqbal, 2020). During crisis and major world-events (such as COVID-19), real-time communication and social media can truly bring the world together in a safe manner.&lt;/p&gt;

&lt;p&gt;Numerous technical challenges arise from designing scalable systems that handle users from different regions. First includes how to initiate the call and inform users that another user wishes to connect. Afterwards, there needs to be a direct connection established to allow for a reliable stream of data to be sent to the recipient(s). Moreover, there are variable network conditions that need to be accounted for such as low bandwith, unreliable connections or firewalls. In addition, there is the consideration of encrypting data sent over the network, and ensuring privacy of users by designing robust systems. This is just a small sample of the set of challenges faced by software engineers, architects and site reliability engineers in designing the world-class systems powering the large-scale social media websites of today.&lt;/p&gt;

&lt;h3 id=&quot;analysis&quot;&gt;Analysis&lt;/h3&gt;

&lt;h4 id=&quot;overview-of-signaling-and-media-streaming&quot;&gt;Overview of Signaling and Media Streaming&lt;/h4&gt;

&lt;p&gt;The high-level goal of real-time communication is to connect a party of people together such that they can communicate with low latency. To achieve this, two connections are established: signaling and media. Signaling is the process of exchange information between different parties, typically associated with events or actions. Media is the actual media being sent, which includes audio and/or video.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/vm5jGcT.png&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Figure 1: The simplest form of peer-to-peer communication.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Signaling is primarily used for session control, network data, media metadata and key material. Session control involves using messages to open, modify and close communication channels. Network data consists of any information for connecting the endpoints, such as obstructions in access. Media metadata is used to transmit metadata such as media types supported, codecs, along with encryption schemes used. Lastly, key material is used for sending encryption keys used to decode sensitive data sent over the network.&lt;/p&gt;

&lt;p&gt;Media streams are used to send the data that users want to experience, such as audio and/or video. Audio and video media is typically encoded using different codecs and can be fine tuned depending on network conditions. Moreover, audio and video media is often susceptible to packet loss, as performance is more critical than losing individual packets of information. Various techniques have been researched and developed over the years to allow for more effective lossy/loseless compression, improved sound quality (echo cancellation, jitter avoidance, etc.) and remidiation of intermittent packet loss.&lt;/p&gt;

&lt;h4 id=&quot;history-of-signaling-and-media-streaming&quot;&gt;History of Signaling and Media Streaming&lt;/h4&gt;

&lt;p&gt;Signaling is not a modern concept - in fact, it was first introduced in the 1800’s as a major component of telephone systems. Electric pulses and audible tones are used to transmit information such as busy signalings, addressing, dial tones and to request service. The rotary dial in 1896, which was later formalized by 1910, introduced the first design of performing such requests which relayed electrical pulses in current flow (“Development of long-distance transmission”, n.d.). Over time, the standards incrementally envolved to take into consideration overseas transmission, newer transmission mediums such as coaxial cabling and applied techniques such as FDM (frequency division multiplexing) to best utilize existing infrastructure.&lt;/p&gt;

&lt;p&gt;In contrast to telephone communication, real-time communication used by social media websites typically uses VoIP (Voice over Internet Protocol) versus PSTN (public switched telephone network). While general concepts remain consistent (such as signaling, connection setup, digitization of analog signals via quantization), data is transmitted over a packet-switched network versus circuit-switched network.&lt;/p&gt;

&lt;p&gt;The first providers of VoIP mirrored solutions of the legacy telephone sys- tems. Second generation providers including Skype adopted large-scale closed networks providing free calling capability with the ability to tap into PSTN 
networks if preferred at cost. The latest generation leverages federated VoIP, which is a form of voice telephony using packets across autonomous domains without requiring switching centers or centralized virtual exchange points. An example would include Google Talk which uses ENUM (E.164 Electronic Number to URI Mapping standard), acting similarly to DNS record types where a telephone number would map to a URI or IP address.&lt;/p&gt;

&lt;p&gt;VoIP calling is implemented using a combination of propriertary and open-source protocols. The foundation was formed in 1928 by Homer Dudley at Bells Labs creating the first electronic voice synthesizer (known as Vocoder). Later, ARPANET (Advanced Research Project Agency) built the first packet-switched network in 1969. By 1973 the first voice data packet was transmitted by MIT, followingly the first audio codec was approved by 1988 (G.722), and then finally by 1991 Autodesk released the first VoIP application (known as Netfone) to the public domain. Development increased substantially after that point, leading to Free World Dialup in 1994 and the first-for-profit VoIP application VocalTec in 1995 (Robert Pepper, 2014).&lt;/p&gt;

&lt;p&gt;The H.323 system specification, instated in 1996, is recommended by the ITU Telecommunication Standardization Sector (ITU-T) as a stack of proto- cols used to provide audio/video communication on packet-switched networks (Margaret Rouse, n.d.). The standard addresses call signaling, control, mul- timedia transport and control, along with bandwith control for peer to peer and multiway conferences. As part of the H.323 family of telecommunication protocols includes H.225.0 RAS (Registration, Admission, Status), H.225.0 Calling Signaling, H.245 control protocol and Real-Time Transport Protocol (RTP) for delivering media.&lt;/p&gt;

&lt;p&gt;SIP (Session Initiation Protocol) was originally standardized in 1999, and is designed to dictate signaling and call setup protocols for IP-based communications (Tien-Thinh Nguyen, Christian Bonnet, 2016). Unlike H.323, which is was standardized by the International Telecommunication Union (ITU), SIP was formalized by the Internet Engineering Task Force (IETF), hence distin- guishing its roots in the internet community rather than telecommunications industry. SIP works in conjunction with other protocols including SDP (Ses- sion Description Protocol) to negotiate and establish call state.&lt;/p&gt;

&lt;p&gt;With respect to streaming media, MPEG-DASH (Dynamic Adaptive Streaming under HTTP, also known simply as DASH) was published in 2012 as the only adaptive bit-rate HTTP streaming solution recognized internation- ally for delivering variable bitrate content. This codec agnostic solution is used by YouTube, Netflix and more. Popular codecs used today for encod- ing video streams in real-time communication includes H.264 (MPEG-4 AVC) introduced in 2003 constituting the majority of tra c, and H.265 (MPEG-H HEVC) introduced in 2013.&lt;/p&gt;

&lt;h4 id=&quot;itu-t-h323-protocols&quot;&gt;ITU-T H.323 Protocols&lt;/h4&gt;

&lt;p&gt;H.323 is a standard that defines a series of protocols to provide audio/video communication sessions across packet-switched networks. The standard, created in 1996 by ITU-T (ITU Telecommunication Standardization Sector) addresses call control and signaling, multimedia control and transport, along with bandwith control for both peer-to-peer and multiway conferences (Margaret Rouse, n.d.). While originally created for use in LAN networks, it was quickly adopted for a variety of IP networks including WANs and the greater internet. The standard has since been iterated on, last updated in 2009, while remaining entirely backwards compatible since its first version. It resides on TCP port 1720.&lt;/p&gt;

&lt;p&gt;Firstly, several definitions will be addressed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.1.&lt;/strong&gt; Terminal The fundamental element in a H.323 system representing a device users would typically use (such as a phone).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.2.&lt;/strong&gt; Multipoint Control Unit (MCU) Device responsible to acting as a conference bridge and allows mixing both video/audio.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.3.&lt;/strong&gt; Gateway Device responsible for enabling communication between H.323 networks and other network types (such as PSTN). An example of using gateways includes allowing enterprise IP phones to communicate with external users via PSTN.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.4.&lt;/strong&gt; Gatekeeper An optional component across the H.323 network which provides a series of services to terminals and gateways. Examples include endpoint registration, admission control, and user authentication.&lt;/p&gt;

&lt;p&gt;Gatekeepers use one of two signaling modes: direct and gatekeeper routed. When direct, endpoints use RAS protocol to learn the endpoint of the remote endpoint and a call is established directly with the remote device. In contrast, when using gatekeeper routed the gatekeeper is used as the intermediary and all signaling passes through it.
Definition. 2.5. Zone The set of endpoints registered to a single Gatekeeper in a H.323 system.&lt;/p&gt;

&lt;p&gt;After the address of the remote terminal is determined the initiating endpoint will leverage H.225.0 call signaling to establish communication with the remote terminal. Fast-connect procedures are defined in H.323 to establish calls using only 2-3 messages, reducing latency. Endpoints generally use RAS protocol to communite with a gatekeeper, while gatekeepers also use RAS protocol to connect with other gatekeepers.&lt;/p&gt;

&lt;p&gt;A terminal would typically invoke a GRQ (Gatekeeper Request) message for discovering gatekeepers that are willing to accept messages. After, applicable gatekeepers would confirm (GCF) and the terminal node would pick its most desirable gatekeeper.&lt;/p&gt;

&lt;p&gt;Upon sending a call initiation signal, the terminal node would perform an admission request (ARQ) to its preferred gatekeeper. In response, the resolves address is returned in the form of an admission confirm message (ACF). Now, the initiating terminal node will send the ARQ to the remote endpoint. The remote endpoint will then likewise send an ARQ and receive an ACF from its preferred gatekeeper. This step is required for ensuring the device is properly authenticated to call the other recipient, and network conditions are capable of sustaining a call.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/KxzwQdK.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Figure 2: Signaling between two endpoints with gatekeepers using H.225.0.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After the call was initiated, the endpoints may further invoke H.245 call control signaling to provide more control. H.245 is capable of sending information required such as encryption, jitter management and preferences (disabling audio and/or video). However, one disadvantage of H.245 is the lengthy four-way protocol handshake required when opening logical channels of a conference. This was alleviated using fastStart in a H.225.0 message (“H.323 Fast Start”, 2015). Later, H.460.6 introduced Extended Fast Connect Feature, providing a one-way handshake.&lt;/p&gt;

&lt;h4 id=&quot;session-initiation-protocol-sip&quot;&gt;Session Initiation Protocol (SIP)&lt;/h4&gt;

&lt;p&gt;Session Initiation Protocol, standardized in 1999, is a signaling protocol used for the initiation, maintenance and termination of real-time voice/video applications (Tien-Thinh Nguyen, Christian Bonnet, 2016). The protocol is text-based, and borrows its structure from Simple Mail Transfer Protocol (SMTP) and Hypertext Transfer Protocol (HTTP). SIP is used alongside Session Description Protocol (SDP) as payload containing media metadata, and was designed to be independent of the transport layer. Therefore, SIP can be transfered over Transmission Control Protocol (TCP), User Datagram Protocol (UDP) or Stream Control Transmission Protocol (SCTP). In addition, SIP transmission is accompanied by encryption using Transport Layer Security (TLS). In contrast with H.323, SIP has been standardized by the IETF rather than the ITU, hence has a stronger connection to the internet community than telecommunications.&lt;/p&gt;

&lt;p&gt;First, several definitions will be addressed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.6.&lt;/strong&gt; User Agent Client (UAC) User Agent capable of receiving responses and sending requests.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.7.&lt;/strong&gt; User Agent Server (UAS) User Agent capable of receiving requests and sending responses.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.8.&lt;/strong&gt; User Agent Network endpoint that receives SIP messages and is capable of managing SIP sessions. Unlike other protocols, SIP requires all user agents to implement both client and server roles, which includes ability to handle both requests and responses.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.9.&lt;/strong&gt; Proxy Server Network endpoint that receives SIP messages and is capable of managing SIP sessions. Unlike other protocols, SIP requires all user agents to implement both client and server roles, which includes ability to handle both requests and responses.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.10.&lt;/strong&gt; Registrar SIP endpoint that accepts REGISTER requests, and records the address from the requesting user agent. Registrars are often used to locate other user agents.&lt;/p&gt;

&lt;p&gt;SIP can be used for both peer-to-peer and multiway conferences. Typically, both user agents will register with the registrar by providing REGISTER requests along with any authentication. Afterwards, the UAC will signal requests (such as an INVITE) to the UAS.&lt;/p&gt;

&lt;p&gt;A selection of common requests/responses is included in Table 1 and 2.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Request Name&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;REGISTER&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Registers the caller’s URI to the registar, used by “To” field&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;ACK&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Confirms user agent receiving final response to INVITE&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;BYE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Signal that the call should be terminated&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;INVITE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Initiate dialog from UAC to UAS to begin call&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;CANCEL&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Cancel any pending requests (such as pre-existing rings)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;REFER&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Ask recipient to takeover existing call (and issue request)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;INFO&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Send any conference metadata while not modifying session state&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MESSAGE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Deliver a text message, typically used by IM clients&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;PUBLISH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Deliver an event to a notification server&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;OPTIONS&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Retrieve the capabilities of an endpoint/user agent&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;Table 1: Session Initiation Protocol Requests&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Response Code&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1xx&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Request was valid and is being processed (asynchronously)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2xx&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Successful completion (for INVITE, it indicates an accept)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3xx&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Call redirection required (INVITE to another user agent)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4xx&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Invalid request (potentialy due to incorrect request syntax)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5xx&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Server failure (potentially internal errors)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;6xx&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Global failure (not limited to one server, can be invalid destination)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;Table 2: Session Initiation Protocol Responses&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Lastly, an extension of SIP is the Session Initiation Protocol for Instant Messaging and Presence Leveraging Extensions (SIMPLE), which can be used for features such as the &lt;code class=&quot;highlighter-rouge&quot;&gt;...&lt;/code&gt; typing indicator, and adds more specialized request/response headers for instant messaging. The first line of requests contains the method along with the request URI.&lt;/p&gt;

&lt;p&gt;On the other hand, the first line of responses is the response code.&lt;/p&gt;

&lt;h4 id=&quot;signal-protocol&quot;&gt;Signal Protocol&lt;/h4&gt;

&lt;p&gt;The Signal Protocol, started in 2013 by Open Whisper Systems, is a non-federated cryptographic protocol allowing for end-to-end encryption of voice/video calls and instant messaging conversations. Originally it was used in the popular messaging app Signal, but later was adopted by other apps including WhatsApp and Messenger/Skype in their optional private conversation modes.&lt;/p&gt;

&lt;p&gt;By implementing end-to-end encryption, the contents of messages and calling signals/media are only available to the sender and recipient(s), and not the intermittent servers and devices. First, a set of long-term identity key pairs, medium-term signed prekey pair and several ephemeral prekey pairs are gen- erated locally and stored securely. After, all the public keys and registration ids are stored in a “key bundle” and registered with the Key Distribution Center. For the sender to send messages, the sender has to be able to get the registration ID and public keys from the receiver, which can be found in the publically accessible key bundle.&lt;/p&gt;

&lt;p&gt;To start a session, the sender uses their identity and medium-term private keys along with the recipient’s set of private keys to determine the master shared secret. The recipient can then receive the master shared secret, decipher and validate it. Afterwards, the two users can send messages to each other.&lt;/p&gt;

&lt;p&gt;While the session is alive, the sender uses the master shared key and the recipient’s ephemeral keys to create a root key, chain key and message chain. This results in a new set of single-use epehemeral keys to encrypt/decrypt future messages. In total, the protocol combines the Double Ratchet algorithm, prekeys, an extended triple Elliptic-curve Diffie-Hellman (X3DH) key agreement protocol, along with using Curve25519, AES-256 and HMAC-SHA256 as cryptographic primitives (Ksenia Kozhukhovskaya, 2017).&lt;/p&gt;

&lt;p&gt;X3DH is used for generating all the required keys for the sender/receiver to communicate, including the shared secret key between the two callers, by registering identity and prekeys to a server. Using this architecture, the caller can retrieve the “prekey bundle” of the callee even when the callee is online.&lt;/p&gt;

&lt;p&gt;Double Ratchet Algorithm is used to provide end-to-end encryption based on the shared secret key retrieved by X3DH. From the shared secret key produced, a “root key” and “sending chain key” are generated. Using a key derivation chain (KDF) from the sending chain key, each subsequent message has a differ- ent epehemeral key by advancing down the chain, and it makes it impossible to decrypt out-of-order messages. In short, when encrypting messages, the sender always forwards the sending chain by one, and generates a new sending chain key and messaging encryption key.&lt;/p&gt;

&lt;p&gt;Finally, AES-256 and HMAC-SHA256 are both 256-bit length encryption functions/block ciphers to protect and encrypt sensitive data. Using the master private keys that are shared across caller/callee, the schemes are used to ensure that the data is essentially non-recoverable without the proper credentials.&lt;/p&gt;

&lt;h4 id=&quot;webrtc-framework&quot;&gt;WebRTC Framework&lt;/h4&gt;

&lt;p&gt;WebRTC (Web Real-Time Communication) is an open-source project providing mobile applications and web-browsers with RTC capabilities via simple APIs. The mission of WebRTC is to “enable rich, high-quality RTC applications to be developed for the browser, mobile platforms, and IoT devices, and allow them all to communicate via a common set of protocols”.&lt;/p&gt;

&lt;p&gt;First, several definitions will be addressed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.11.&lt;/strong&gt; Session Description Protocol (SDP) Format used in describing and negotiating a session’s profile (which includes properties and parameters such as media types and encryption keys). SDP can use attributes extending the protocol’s capabilitiesas key/value pairs, and is otherwise a text- based format with one field per line.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.12.&lt;/strong&gt; NAT (Network Address Translation) Process for translating local IP addresses to public IP addresses, often used for security reasons and conserves legally registered IP addresses (due to limitations with IPv4 bit count).&lt;/p&gt;

&lt;p&gt;NATs typically work in four ways: full cone (internal address maps to external address and any external host can send requests), address-restricted cone (any host can send to an externally mapped host/port if and only if that host/port previously sent to the host), port-restricted cone (similar to address-restricted cone, except not only did the receiver need to have previously sent to the same host, but also the matching sender port), and lastly symmetric (where a new mapping is used for each request).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.13.&lt;/strong&gt; STUN (Session Traversal Utilities for NAT) Lightweight and simple service which provides the public IP address of its caller, used to reply back its IP address to the original caller to establish an IP address; typically used in non-symmetric NATs (full-cone, address-restricted, port-restricted).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.14.&lt;/strong&gt; TURN (Traversal using Relays around NAT) Computationally expensive relay for sending messages/media to a destination, typically used in symmetric NATs where the public IP cannot be discoverable and instead requires a statically defined external service to send information to the requesting caller.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.15.&lt;/strong&gt; ICE (Interactive Connectivity Establishment) Standard used for performing NAT (Network Address Translation) traversals. ICE deals with returning candidate agent addresses (local, reflexive such as STUN and relayed such as TURN).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition. 2.16.&lt;/strong&gt; Trickle ICE Optimization of ICE specification providing parallelized connectivity checks across the candidate addresses, reducing the overall initiation time.&lt;/p&gt;

&lt;p&gt;There are several core components of the WebRTC framework that is exposed through the JavaScript APIs. Some examples include “getUserMedia” that is used to acquire the audio/video media. In addition, “RTCPeerConnection” is used for performing signal processing, security, peer-to-peer communication and bandwith management. Another core capability is the “RTCDataChannel” for allowing bidirectional communication among peers for sending media using a system based on WebSockets (MDN Contributors, 2020).&lt;/p&gt;

&lt;p&gt;The first task in establishing a WebRTC connection is to use a signaling server for resolving the connection. The role of the signaling server is to act as an intermediary and allow the peers to establish a connection with minimizing pri- vate information exposure. WebRTC does not mandate any specific transport mechanism. Instead, WebRTC leverages SDP payloads and ICE to determine candidates for establishing the connection.&lt;/p&gt;

&lt;p&gt;For exchanging media WebRTC uses SDP to execute the offer and answer mechanism across peers. Unfortunately, firewalls and NATs are often used in the real-world to both protect private IPs and limit the number of registered IP addreses due to limited IPv4 addressing. However, NAT mappings would occur at the network layer, and hence will change the TCP/UDP packet headers but leave SDP payloads unchanged hence leaving them unaware of handling external NAT IP addresses and port restrictions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/Cq1qLlL.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Figure 3: Example of simple signaling and media transfer without NATs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Depending on the type of NAT (full cone, address-restricted/port-restricted cone or symmetric), a different configuration of services is required. STUN is used in the case of asymmetric NATs, where it is simply invoked to determine the public IP address and then that can be used for media transfer. This is a lightweight solution and is common in practice. Unfortunately, for symmetric cones a relay solution is required where TURN servers will be used as the intermediary endpoints. The disadvantage of this approach is that TURN servers are expensive, add additional latency and will be another source of failure among the media streaming path.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/PEEHjtJ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Figure 4: Example of signaling and media transfer between coned/reflexive NATs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Popular users of the WebRTC users includes Facebook with over 300 million monthly active users, Discord and Skype (Chad Hart, 2017).&lt;/p&gt;

&lt;h4 id=&quot;real-time-streaming-protocol-rtsp&quot;&gt;Real-Time Streaming Protocol (RTSP)&lt;/h4&gt;

&lt;p&gt;Real-Time Streaming Protocol (RTSP), standardized in 1998 by the IETF, is a network control protocol for controlling streaming media servers (Ivn Santos- Gonzlez, Alexandra Rivero-Garca, Jezabel Molina-Gil, Pino Caballero-Gil, 2017). RTSP is not responsible for the streamed data itself, which is often handled by the Real-time Transport Protocol (RTP).&lt;/p&gt;

&lt;p&gt;Instead, it facilitates capabilities such as play and pause. The protocol is similar to HTTP, with several exceptions such as RTSP being stateful and resides on both TCP/UDP ports 554 (although UDP is rarely ever used).&lt;/p&gt;

&lt;p&gt;RTSP supports several types of requests, including several overlapping with HTTP. “OPTIONS”, similar to HTTP, returns the accepted request types by the server. “DESCRIBE” requests are used for obtaining SDP presentation descriptions, which contain metadta such as the list of media streams that are controlled by the aggregate URL, bitrate, mime type, etc. Lastly, there are “PLAY”, “PAUSE” and “TEARDOWN” requests.&lt;/p&gt;

&lt;p&gt;Popular client implementations of this protocol include VLC media player, Skype, Spotify, QuickTime and Windows Media Player. In addition, YouTube uses RTSP as an available streaming option when the mobile HTTPS site is viewed on desktop.&lt;/p&gt;

&lt;h4 id=&quot;real-time-control-protocol-rtcp&quot;&gt;Real-Time Control Protocol (RTCP)&lt;/h4&gt;

&lt;p&gt;Real-Time Control Protocol (RTCP) is often used in conjunction with RTP to provide out-of-band (signaling running on a dedicated channel away from media channels in PTSN) control information and statistics for an RTP session. RTCP provides feedback on the quality of service including roundtrip delay time, packet delay variation, packet loss and packet counts. This allows for adaptive capabilities such as Dynamic Adaptive Streaming over HTTP (DASH) to be implemented (“RTP Control Protocol (RTCP)”, 2017). RTP is generally executed on an even-numbered UDP port, and RTCP on the next odd-numbered port. While RTCP does not provide any encryption/authentication methods, Secure Real-time Transport Protocol (SRTP) provides such capabilities.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/84TF2Oa.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Figure 5: Example of signaling between two peers in WebRTC.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/MJBciLm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Figure 6: Example of ICE negotiation in WebRTC.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Web-Browser&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Supported Versions&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Microsoft Edge&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;12+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Google Chrome (Desktop)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;28+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Mozilla Firefox&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;22+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Opera&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;18+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Safari&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;11+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Google Chrome (Android)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;28+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Mozilla Firefox (Android)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;24+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Opera (Mobile)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;12+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;iOS MobileSafari/WebKit&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;iOS11+&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;Table 3: Browsers with WebRTC Support&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;RTCP provides three functionalities. First, RTCP provides statistics on qual- ity of service during media distribution. This can be used, as mentioned earlier, for the implementation of DASH alorithms and paging Engineers to look into potential network disruptions. Secondly, RTCP provides Canonical Name Records (CNAME) to conference participants and allows for effective third-party monitoring. Lastly, RTCP is often used for reaching all conference participants, as RTP only transmits via media source. RTCP reporting is applied to all participants of a conference, and is randomized in reporting time to avoid unintended synchronization of reporting (typically intervals around five seconds are used). As a best practice to avoid network congestion, RTCP bandwith usage should not be higher than 5% of overall session bandwith to prevent causing degraded performance.&lt;/p&gt;

&lt;p&gt;Several types of messages are supported by RTCP, and can be extended further to include custom packets. Sender report (SR) is periodically sent by active senders in conferences to report reception and transmission statistics. Receiver report (RR) is for receivers of RTP packets, and likewise sends quality reports to senders. Source description (SDES) provides CNAMEs to session participants for use in third-party monitoring solutions. Goodbye (BYE) is used to shut down a tream of data.&lt;/p&gt;

&lt;h4 id=&quot;real-time-transport-protocol-rtp&quot;&gt;Real-Time Transport Protocol (RTP)&lt;/h4&gt;

&lt;p&gt;Real-Time Transport Protocol (RTP), standardized by the IETF in 1996, is a networking protocol for audio and video delivery over IP networks. It is often used in conjunction with SIP and RTCP to create and ensure quality transmission of media. RTP is designed for real-time transfer of media streams and provides capabilities such as detection of packet loss, out-of-order delivery, jitter compensation and IP multicast support. RTP is based on application- layer framing, where the protocol functions are implemented in the application rather than operating system.&lt;/p&gt;

&lt;p&gt;RTP supports a range of multimedia formats and is extensible by design. By providing profiles and one or more payload formats for each class of application (such as audio or video), RTP supports definining mapping codecs to payload format codes inside profiles, which then describes the transport method for the encoded data. For example, Secure Real-Time Transport Protocol (SRTP) is an RTP profile for providing cryptographic services for transferring payload data. RTP senders would capture the media, encode it, then transmits it as an RTP packet with the appropriate timestamps and increasing sequence numbers. RTP receivers then detect missing packets and may reorder packets.&lt;/p&gt;

&lt;p&gt;Afterwards, the stream can be decoded and presented to the user.
Packet headers for RTP support various mandatory fields, as shown in the figure below. Version is used to indicate the current version of the protocol used (2 bits, where the current version is 102). P (Padding, 1 bit) may indicate extra padded bytes at the end of a header, typically used due to size requirements imposed by encryption algorithms. X (Extension, 1 bit) is used to indicate presence of an extension header between header and the payload. CC (CSRC count, 4 bits) indicates the number of CSRC identifiers fllowing SSRC. Sequence numbers are incremented for each RTP data packet sent, used to implement out-of-order delivery and detect lost packets. SSRC (synchronization source identifier, 32 bits) is used to identify the source of the stream, while CSRC (contributing source ids, 32 bits each) are used to enumerate contributing sources to the stream. Lastly, the optional header extension would include a 16 bit profile-specific identifier and a 16 bit length specifier, with the custom extension header data following.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/5Expq9c.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Figure 8: Example of an RTP packet header.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;audio-streaming-codecs&quot;&gt;Audio Streaming Codecs&lt;/h4&gt;

&lt;p&gt;The process of encoding and decoding audio data is handled by an audio codec (coder/decoder). In real-time communication, the balance between having high-quality audio and low-bandwith requirements is a power struggle that often requires compromises from either side. The two general categories of factors affecting encoded audio is the codec chosen and the details about the source audio’s contents and format.&lt;/p&gt;

&lt;p&gt;Different codecs provide a variety of parameters to tune allowing for vari- able bit rate, audio frequency bandwith and many other custom fields. Audio codecs are based on advanced numerical computational algorithms and can provide either lossless or lossy compression. AAC (Advanced Audio Coding) is a common codec defined by the MPEG-4 (H.264) standard, used by Blue-ray disks, HDTV, and songs purchased from iTunes (MDN contributors, 2019). However, the format is protected by numerous patents making distribution less predictable. On the other hand, G.722 codec is built with voice compression in mind, is low-latency and uses Adaptive Differential Pulse Code Modulation (ADPCM) to reduce recording size. G.722 is mandated by the WebRTC specification and is typically used for WebRTC connections. Lastly, MP3 (MPEG-1 Audio Layer III) is one of the most common codecs, where MPEG-1 MP3 is generally used for music and MPEG-2 MP3 is used for simpler sounds and requires less space. Moreover, MP3 patents expired as of 2017 in the United States making it supported by all popular web-browsers.&lt;/p&gt;

&lt;p&gt;The WebRTC API does not mandate if a particular can be used in a track, but instead requires support VP8 and H.264’s constrained baseline profiles for video and G.711 PCM (A-law) and G.711 PCM (u-Law) audio codecs for Chrome, Firefox and Safari browsers.&lt;/p&gt;

&lt;h4 id=&quot;video-streaming-codecs&quot;&gt;Video Streaming Codecs&lt;/h4&gt;
&lt;p&gt;Video encoding is the process of turning raw video into a digital format to be viewed on different devices. Similar to audio codecs, video codecs vary in behavior and specialization depending on use-case, and are often either lossless or lossy in nature. Encoded videos are wrapped into a “video container” (such a .mp4, mov), which contains the video codec, audio codec and associated metadata. The key difference between a container format and a codec is that the codec is at the source and playback to compress and decompress respectively, while the container can be used to determine which programs accept the stream and holds the different components (audio, video, closed captioning) together.&lt;/p&gt;

&lt;p&gt;The most common encoding for streaming is MPEG-4 H.264/AVC (Advanced Video Coding), developed by the International Telecommunications Union (ITU) and International Organization for Standardization/International Electrotechnical Commission (ISO/IEC) Moving Picture Experts Group. H.264/AVC has capabilities of being packaged into a variety of container types including .mov, .mp4, .3GP and more.&lt;/p&gt;

&lt;p&gt;MPEG-5 H.265/HVEC is a newer codec, which has improved compression efficiency and supports 8k resolution. However, the market-share is only around 10% due to royalty complications (Traci Ruether, 2019). To address this, AV1 was created in a partnership with several leading tech companies (Google, Mi- crosoft, Amazon, Netflix, and more) to create a performant royalty-free codec. Google created the VP9 codec as a royalty-free and more performant version of HVEC, however it is not supported on Apple devices and is often considered to be “AV0”.&lt;/p&gt;

&lt;h4 id=&quot;dynamic-adapative-streaming-over-http-dash&quot;&gt;Dynamic Adapative Streaming over HTTP (DASH)&lt;/h4&gt;

&lt;p&gt;Dynamic Adaptive Streaming over HTTP (MPEG-DASH, otherwise known simply as DASH) was standardized in 2012 to provide adaptive bitrate streaming for media over HTTP web servers. DASH works by taking content and breaking it down into smaller HTTP-based file segments, where each segment contains a small interval of content. Each individual segment is then broken down into different bit rates. While the media is streamed, the client applies a bit rate adaption (ABR) algorithm that selects the appropriate segment such that the content can be downloaded in time without causing rebuffering/stalls and maximizes quality.&lt;/p&gt;

&lt;p&gt;DASH uses TCP as the chosen transport protocol, and remains agnostic to codecs (meaning it supports various formats including H.264, H.265, VP9), ABR logic and the underlying application layer protocol. Alongside the individual segments containing intervals of streamed data, DASH uses a media presentation description (MPD) to describe segment information (URL, timing, bit rates, etc.), and is presented using a variety of data-structures such as timelines or lists. While there is no restrictions on the type of media data, the specification provides recommendations on using two types of containers: MPEG-2 Transport stream or an ISO base media file format (such as MP4).&lt;/p&gt;

&lt;p&gt;Adoption is widespread for DASH, including support by YouTube and Netflix and VLC. While not directly supported in HTML5, there are open-source JavaScript implementations for DASH adding the functionality. Moreover, when combined with WebGL, HTML5-based DASH allows for streaming of 360 degrees content. Alongside developer and product support, content distribution networks (CDN) support for DASH is vast, including Akamai, Amazon CloudFront, CloudFlare and Azure Media Services.&lt;/p&gt;

&lt;p&gt;HTTP Live Streaming (HLS), released in 2009, is an alternative HTTP-based adaptive bitrate streaming protocol developed by Apple (Max Wilbert, 2020). Similar to DASH, HLS breaks the stream into a sequence of smaller HTTP-based file downloads in a variety of different bitrates. After, the list of available streams encoded at different bitrates is sent as an extended M3U playlist to the client. Unlike RTP, HLS allows for traversing firewalls and NATs that would otherwise allow regular HTTP tra c to travel through. Later versions of the protocol also introduced subtitle support.
The architecture of HLS is comprised of three parts: server, distributor and client. The server is responsible for preparing the video for delivery, encoding encoding the video files in H.264 format in variable bitrates as MP3, AAC, AC-3 or EC-3, and then encapsulated in MPEG-2 Transport Stream. After, the segmenter will divide the MPEG-2 TS file into equally sized segments, and then create the index file for fragmented files as an m3u8 file. The distributor will then act as a regular HTTP web server, and deliver the required m3u8 playlist file and ts segment files required to stream the content. Lastly, the client will retrieve the m3u8 file containing the index of segments, and then retrieve the necessary segments from the distributor.&lt;/p&gt;

&lt;h4 id=&quot;multiway-calling-architecture&quot;&gt;Multiway Calling Architecture&lt;/h4&gt;

&lt;p&gt;WebRTC media streaming natively supports communication across two different peers, but often real-time communication applications support multiway calling involving numerous peers. Multiway conferences for voice and video can be supported using three architectures: mesh, mixing and routing (Tsahi Levent-Levi, 2019). In addition, signaling often uses an intermediary centralized server acting as an anonymous “peer”, and relays signaling using ICE candidates (such as STUN or TURN).&lt;/p&gt;

&lt;p&gt;Mesh routing involves an &lt;code class=&quot;highlighter-rouge&quot;&gt;n^2&lt;/code&gt; amount of linkages, where n is the number of peers, which is not scalable to many users and requires substantial amounts of bandwith. Mixing leverages an MCU (Multipoint Conferencing Unit) which acts as a centralized point where multiple streams from individual peers are combined into a single unified stream. However, despite the simplicity in design, it comes without flexibility such as client-specific processing because the streams are combined at the relay source.&lt;/p&gt;

&lt;p&gt;Routing leverages an SFU (Selective Forwarding Unit), which instead acts as the router of the media (Tsahi Levent-Levi, 2019). In contrast to mixing, routing will send individual streams directly to other peers allowing for more client-sided flexibility in terms of processing. Three approaches are applied for routing: multi-unicast, simulcast and SVC. Multi-unicast is the trivial approach, where users would send streams to the SFU and the SFU would decide where to route, not performing any bit rate adaption. On the other&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/PZrSudz.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Figure 8: Example of multiway mesh streams.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/Iz27xCu.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Figure 9: Example of multiway mixing streams.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/IHfZFTV.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Figure 10: Example of multiway routing streams.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;hand, simulcast will accept multiple streams of varying qualities and then will send the supported ones (based on network conditions and device capabilities) to the other peers.&lt;/p&gt;

&lt;p&gt;Lastly, SVC (scalable video coding) uses a similar methodology as simulcast, but instead of sending disjoint streams of varying bitrates, SVC sends a layered stream of increasing quality where particular layers can be “peeled” off the top to reduce quality. This is an enhancement over simulcast because it reduces computation time and allows error corrections to occur only at base levels; it was introduced to WebRTC in the VP9 video codec.&lt;/p&gt;

&lt;h3 id=&quot;case-studies&quot;&gt;Case Studies&lt;/h3&gt;
&lt;h4 id=&quot;skypes-p2p-signaling-protcol-2003&quot;&gt;Skype’s P2P Signaling Protcol (2003)&lt;/h4&gt;

&lt;p&gt;Skype is a VoIP client developed by Microsoft allowing users to place audio and video calls over the internet. Skype uses an overlayed peer-to-peer network, similar to its file sharing predecessor Kazaa (Salman A. Baset, Henning G. Schulzrinne, 2004). There are two types of nodes in the architecture: ordinary hosts and super nodes (SN). An ordinary node is any Skype client that is used for issuing voice and video calls. Super nodes are also Skype clients, however they are promoted to SN once it is identified that they have a public IP address, performant hardware (RAM, CPU) and network bandwith. In addition, the login server is a critical piece of Skype infrastructure as it handles the login credentials of users and in later Skype versions the friends lists of users. Moreover, SkypeOut and SkypeIn are servers used to bridge VoIP with PSTN, however it is not used in pure VoIP calls.&lt;/p&gt;

&lt;p&gt;Every Skype node uses a variant of the STUN/TURN protocol to identify NAT and firewall restrictions of users. When the SC is loading, it first sends an HTTP request to determine if there should be a software update. After, a connection to a SN is established. A critical component of Skype clients is the host cache (HC), which is built and refreshed regularly to contain a list of SN capped at a length of 200. If none of the SN inside the HC are reachable, Skype resorts to establishing a TCP connection to a bootstrapped list of 8 hardcoded SN addresses - if that does not work either then Skype fails to login. After SC is connect to a SN, the client applies the username/password to authenticate with the Skype login server.&lt;/p&gt;

&lt;p&gt;Skype user search leverages a Global Index (GI) technology (Salman A. Baset, Henning G. Schulzrinne, 2004). First, the SC will ask the SN over UDP if it knows any users matching the regular expression. If an SN does not know, then it will provide 8 addresses of SN nodes over TCP to the SC to further query. This process repeats with 16, 32, and exponentially many more nodes. After an abritrary cutoff, if none are found, the login server is requested (which is always invoked in the case of no matching usernames). Repeated queries are cached locally at the client.&lt;/p&gt;

&lt;p&gt;The Skype protocol has no silence suppression, meaning it still sends UDP packets containing null noise even when muted. There are two benefits to this design choice, namely preventing reapplying UDP bindings and in the case of TCP being used it prevents drops in the TCP congestion window which would reduce preliminary RTT time until it ramps back up. The codec of choice used by Skype is iCodec, with a minimum bandwith requirement of 2Kb/second (Salman A. Baset, Henning G. Schulzrinne, 2004). Lastly, it was observed that in conferences, the media is not fully meshed, meaning the most powerful machine is elected to be the host and collect and later distribute the streams to the remaining hosts, as show in the figure below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/FDQAqyr.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Figure 11: Example conference signaling without full mesh.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h3&gt;
&lt;h4 id=&quot;resulting-architecture-of-rtc-systems&quot;&gt;Resulting architecture of RTC systems&lt;/h4&gt;
&lt;p&gt;This post provides a high-level overview of different protcols, standards and codecs used to implement scalable real-time communication services such as video calling. Various protocols and technologies are involved in the signaling, encoding, and delivery of media over networks. Over time, numerous opti- mizations have been applied to reduce the number of handshakes required to establish connections, save bandwith and improve call quality. By applying the techniques applied in this post, it becomes possible to get a high-level view of designing a large-scale system supporting numerous concurrent users across ranging network setups such as private IP addresses guarded by fire- walls. In the future, frameworks such as WebRTC will become more mature, codecs such as H.265 will have widespread adoption and protocols will be added making it easier than ever to keep the world connected and together by using real-time communication.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;p&gt;[1] Mansoor Iqbal (2020). WhatsApp Revenue and Usage Statistics. Business of Apps (2020). Retrieved April 12, 2020, from https://www.businessofapps.com/data/whatsapp-statistics/&lt;/p&gt;

&lt;p&gt;[2] (n.d.) Development of long-distance transmission. ENCYCLOPDIA BRITANNICA. Retrieved April 12, 2020 from https://www.britannica.com/technology/telephone/Transmission&lt;/p&gt;

&lt;p&gt;[3]Robert Pepper (2014). The History of VoIP and Inter- net Telephones GetVoIP. Retrieved April 12, 2020, from https://getvoip.com/blog/2014/01/27/history-of-voip-and-internet- telephones/&lt;/p&gt;

&lt;p&gt;[4] Jan Ozer (2011). What Is MPEG DASH? Streaming Media. Retrieved April 12, 2020, from https://www.streamingmedia.com/Articles/ReadArticle.aspx?ArticleID=79041&lt;/p&gt;

&lt;p&gt;[5] Margaret Rouse (n.d.). H.323 Search Networking. Retrieved April 12, 2020, from https://searchnetworking.techtarget.com/definition/H323&lt;/p&gt;

&lt;p&gt;[6] Tien-Thinh Nguyen, Christian Bonnet (2016). IP Mobility Management for Future Public Safety Networks Wireless Public Safety Networks 2. Retrieved April 12, 2020, from https://www.sciencedirect.com/topics/computer-science/session- initiation-protocol&lt;/p&gt;

&lt;p&gt;[7] (2015). H.323 Fast Start. Dialogic.. Retrieved April 12, 2020, from https://www.dialogic.com/webhelp/BorderNet2020/1.1.0/WebHelp/h323 faststart.htm
 31&lt;/p&gt;

&lt;p&gt;[8] Ksenia Kozhukhovskaya (2017). Demystifying the Signal Protocol for End-to-End Encryption (E2EE) Cloudboost. Retrieved April 12, 2020, from https://blog.cloudboost.io/demystifying-the-signal-protocol-for-end- to-end-encryption-e2ee-3e31830c456f&lt;/p&gt;

&lt;p&gt;[9] MDN Contributors (2020). WebRTC API. Mozilla Developer Network. Retrieved April 12, 2020, from https://developer.mozilla.org/en- US/docs/Web/API/WebRTC API&lt;/p&gt;

&lt;p&gt;[10] Chad Hart (2017). WebRTC: One of 2016’s Biggest Technologies No One Has Heard Of Web RTC World. Retrieved April 12, 2020, from http://www.webrtcworld.com/topics/webrtc-world/articles/428444- webrtc-one-2016s-biggest-technologies-no-one-has.htm&lt;/p&gt;

&lt;p&gt;[11] Ivn Santos-Gonzlez, Alexandra Rivero-Garca, Jezabel Molina-Gil, Pino Caballero-Gil (2017). Implementation and Analysis of Real-Time Streaming Protocols US National Library of Medicine. Retrieved April 12, 2020, from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5424723/&lt;/p&gt;

&lt;p&gt;[12] (2017). RTP Control Protocol (RTCP) SDX Central. Retrieved April 12, 2020, from https://www.sdxcentral.com/resources/glossary/rtp-control-protocol-rtcp/&lt;/p&gt;

&lt;p&gt;[13] MDN contributors (2019). Web audio codec guide Mozilla Developer Network. Retrieved April 12, 2020, from https://developer.mozilla.org/en- US/docs/Web/Media/Formats/Audio codecs&lt;/p&gt;

&lt;p&gt;[14] Traci Ruether (2019). Video Codecs and Encoding: Everything You Should Know (Update) Wowza Media Streams. Retrieved April 12, 2020, from https://www.wowza.com/blog/video-codecs-encoding
  32&lt;/p&gt;

&lt;p&gt;[15] Max Wilbert (2020). What is HLS streaming and when should you use it? dacast. Retrieved April 12, 2020, from https://www.dacast.com/blog/hls-streaming-protocol/&lt;/p&gt;

&lt;p&gt;[16] Tsahi Levent-Levi (2019). WebRTC Multiparty Architectures BlogGeek. Retrieved April 12, 2020, from https://bloggeek.me/webrtc-multiparty- architectures/&lt;/p&gt;

&lt;p&gt;[17] Salman A. Baset and Henning G. Schulzrinne (2004). An Analysis of the Skype Peer-to-Peer Internet Telephony Protocol Columbia University. Retrieved April 12, 2020, from http://www1.cs.columbia.edu/ salman/publications/skype1 4.pdf&lt;/p&gt;</content><summary type="html">I recently did an internship at Facebook where I was part of the RTC (Real-Time Communications) org, responsible for the products and infrastructure powering voice/video calling across Facebook’s family of apps (such as Messenger and Instagram). My team was responsible for the P2P and multiway calling protocols, including lower-level services written in C++ and platform integrating with partner teams in PHP.</summary></entry><entry><title type="html">Living in Seattle for Four Months</title><link href="http://horatiulazu.ca/blog/coop/2020/03/26/seattle.html" rel="alternate" type="text/html" title="Living in Seattle for Four Months" /><published>2020-03-26T19:49:29-04:00</published><updated>2020-03-26T19:49:29-04:00</updated><id>http://horatiulazu.ca/blog/coop/2020/03/26/seattle</id><content type="html" xml:base="http://horatiulazu.ca/blog/coop/2020/03/26/seattle.html">&lt;p&gt;I am fortunate to have spent three (not four) months in Seattle, Washington at Facebook! Here is an overview of some activities and sightseeing accomplished during the term.&lt;/p&gt;

&lt;p&gt;Overall, the Seattle winter weather didn’t really play in the favor of outdoor activities (fact: January had 28 days of rain), but nonetheless it was a fun term with friends and nice co-workers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/GhX7YVj.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;why-end-early&quot;&gt;Why end early?&lt;/h3&gt;
&lt;p&gt;The Coronavirus (COVID-19) essentially sprung from being ever so distant in Wuhan, China but eventually landed at the doorsteps in Washington. After border restrictions were put in place, the University of Waterloo, Canadian Government and Visa Sponsorer (Cultural Vistas) all recommended to return.&lt;/p&gt;

&lt;p&gt;While I originally refused (as I wanted to spend more time at Facebook), eventually CECA (UW’s co-op department) told Facebook to make co-ops return. In retrospect, it was the right decision for safety.&lt;/p&gt;

&lt;h3 id=&quot;living-situation&quot;&gt;Living Situation&lt;/h3&gt;
&lt;p&gt;The corporate housing (&lt;a href=&quot;https://www.624yale.com/&quot; target=&quot;_blank&quot;&gt;624 Yale&lt;/a&gt;) was quite good - I’d place it between Bloomberg (&lt;a href=&quot;https://www.92y.org/residence&quot; target=&quot;_blank&quot;&gt;92y&lt;/a&gt;) and Citadel (&lt;a href=&quot;https://www.marqueeblock37.com/&quot; target=&quot;_blank&quot;&gt;Block 37 Marquee&lt;/a&gt;) in terms of desirability. Fully furnished 2 bedroom 2 bathroom in South Lake Union made it easy to get to Facebook Dexter, and it was in a safe and quiet neighborhood. The bathrooms and kitchen were fully equipt with just about anything you’d need.&lt;/p&gt;

&lt;p&gt;The bi-weekly cleaners were also a plus, in addition to in-suite laundary. The building’s gym was quite poor compared to Citadel’s rooftop gym, or even Bloomberg’s 92y gym. There weren’t any other amenities offered in the building, such as a swimming pool, and the lobby felt small. In addition, there was no 24/7 reception. However, it was substantially quieter than both Citadel and Bloomberg’s, so I enjoyed it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/ydZDcHM.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Seattle’s already dark and gloomy, the lack of lighting was a major issue during the winter rainy months.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/hN3qWfH.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;swag&quot;&gt;SWAG&lt;/h3&gt;
&lt;p&gt;Of course, not an accomplishment or venture but the most important part of any internship; during my internship at Facebook I was on the Messenger RTC (Real-Time Communications) organization, more specifically focusing on call signaling. Not pictured here is a free Facebook Portal Mini.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/UZE1x9E.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;mount-si&quot;&gt;Mount Si&lt;/h3&gt;
&lt;p&gt;On the second weekend, I ventured out and hiked up Mount Si. I wasn’t entirely certain what to expect, but it turned out to be a fairly involved climb. The &lt;a href=&quot;https://www.strava.com/activities/3026758376&quot; target=&quot;_blank&quot;&gt;route&lt;/a&gt; can be seen below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/6l3QX0Z.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Coming in at around 1000m elevation gain (3300ft) over 14km roundtrip (8.7 miles), the route was certainly more involved than the Muir Woods trail in San Francisco several terms ago. The biggest difficulty wasn’t at all the actual route, but the lack of preparation on my part.&lt;/p&gt;

&lt;p&gt;More specifically, I underestimated the amount of snow there was and I grossly missed on equipment such as spikes and poles. On several occasions I slipped on the ascent/descent, but slow and steady went ok in the end… in the future: gloves, spikes and poles.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/n5dEGnX.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/HRo4oK7.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/QoIdwdA.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;mount-squak&quot;&gt;Mount Squak&lt;/h3&gt;
&lt;p&gt;Another smaller hike followed, which wasn’t anywhere near as challenging and the view was just fog. Nonetheless, some statistics for that hike here.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/YcRUsw3.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;mount-snoqualmie&quot;&gt;Mount Snoqualmie&lt;/h3&gt;

&lt;p&gt;“Work from home Wednesdays”, aka paid ski trip for the entire Bellevue office.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/KQ4Ytdu.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;vancouver&quot;&gt;Vancouver&lt;/h3&gt;

&lt;p&gt;Not the best weather, nor went up Whistler mountain, but nonetheless touring Stanley park was enjoyable.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/v8UvEur.jpg&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;https://i.imgur.com/t1I7XZR.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/dG3FAcy.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ride-to-kenmore&quot;&gt;Ride to Kenmore&lt;/h3&gt;
&lt;p&gt;One of my friends from high-school had just started full-time at Facebook Seattle and lent me his hybrid Giant bike. The Burke Gilman trail was particularily pleasant to ride on. 
&lt;img src=&quot;https://i.imgur.com/TBrJ0AY.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/4bhbE5q.jpg&quot; /&gt;&lt;/p&gt;</content><summary type="html">I am fortunate to have spent three (not four) months in Seattle, Washington at Facebook! Here is an overview of some activities and sightseeing accomplished during the term.</summary></entry><entry><title type="html">Living in Chicago for Four Months</title><link href="http://horatiulazu.ca/blog/coop/2019/07/16/chicago.html" rel="alternate" type="text/html" title="Living in Chicago for Four Months" /><published>2019-07-16T19:49:29-04:00</published><updated>2019-07-16T19:49:29-04:00</updated><id>http://horatiulazu.ca/blog/coop/2019/07/16/chicago</id><content type="html" xml:base="http://horatiulazu.ca/blog/coop/2019/07/16/chicago.html">&lt;p&gt;I am fortunate to have spent an internship at Citadel Securities in Chicago, Illinois.&lt;/p&gt;

&lt;p&gt;Citadel Securities is the largest market maker in the United States responsible for executing over 20% of US equity trades, including over 39.5% of retail shares traded. You can watch &lt;a href=&quot;https://www.youtube.com/watch?v=2u007Msq1qo&quot; target=&quot;_blank&quot;&gt;this video&lt;/a&gt; outlining high frequency trading (plus you get to see my co-workers, it was filmed behind my desk!).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-plane.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The provided corporate housing is a 2 bedroom + 2 bath luxury condo suite shared with 1 roommate being around 5 minutes walk from the office in the heart of the loop.&lt;/p&gt;

&lt;p&gt;This has been by far the best corporate housing so far, we even had a weekly cleaner and lots of amenities including swimming pool, rooftop terrace/gym, billiards, and more!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-living.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-kitchen.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-bedroom.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The views from the corporate housing were great too.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-view1.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-view2.jpg&quot; /&gt;&lt;/p&gt;

&lt;!-- &lt;img src=&quot;/blog/assets/chicago-lightning-1.jpg&quot;/&gt; --&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-lightning.gif&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is the view of Chicago from the Planetarium.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-planetarium-view.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The following are pictures of River North.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-river-north-1.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-river-north-3.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-river-north-2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;View of Chicago from the Botanical Garden.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-botanical.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;John Hancock building on a foggy day.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-john-hancock.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-john-beach.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Views from John Hancock Tower 96th floor&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-john-north.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-john-east.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-john-south-east.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-john-south.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ken Griffin, the founder of Citadel, paid over $300 million for this painting.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-painting.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Citadel HQ (outside)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-citadel.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Chicago Botanical Garden&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-cascade.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-garden1.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-garden2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-garden3.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-garden4.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/chicago-garden5.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Lastly … &lt;a href=&quot;https://medium.com/@LumpyBatter/what-is-kobe-beef-and-why-is-it-so-expensive-4b76674ed2c1&quot; target=&quot;_blank&quot;&gt;3oz Wagyu Kobe Beef&lt;/a&gt; :)
&lt;img src=&quot;/blog/assets/chicago-steak.jpg&quot; /&gt;&lt;/p&gt;</content><summary type="html">I am fortunate to have spent an internship at Citadel Securities in Chicago, Illinois.</summary></entry><entry><title type="html">Living in San Francisco for Four Months</title><link href="http://horatiulazu.ca/blog/coop/2019/04/20/cali-round-1.html" rel="alternate" type="text/html" title="Living in San Francisco for Four Months" /><published>2019-04-20T19:49:29-04:00</published><updated>2019-04-20T19:49:29-04:00</updated><id>http://horatiulazu.ca/blog/coop/2019/04/20/cali-round-1</id><content type="html" xml:base="http://horatiulazu.ca/blog/coop/2019/04/20/cali-round-1.html">&lt;p&gt;Starting off, I’m roughly four months late! I decided to do one of these posts for each internship, and since I’m starting my next co-op in Chicago at Citadel Securities in less than 2 weeks, and I have an exam in 3 days, there’s no better time to procrastinate.&lt;/p&gt;

&lt;p&gt;In my opinion, road biking let me explore the regions around San Francisco much better than I would be able to otherwise see (with the exception of having a car), so I hope you enjoy the views :-)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-11.JPG&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Golden Gate Bridge, fun fact is that it actually has an incline which is noticable while cycling&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-20.JPG&quot; /&gt; &lt;!-- remove 7 --&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;View from the Golden Gate Bridge&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-2.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Alongside Highway 1, around 2/3rds the way towards San Francisco form Santa Cruz&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-4.JPG&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Alongside Highway 1, halfway between San Francisco and Santa Cruz&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-3.JPG&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;View of downtown San Francisco at sunset from Twin Peaks&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-5.JPG&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Alpine Dam, south of Fairfax&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-10.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Overlooking Mill Valley&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-8.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Mount Tamalpais West Peak&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-18.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Mount Tamalpais East Peak&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-14.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Overlooking Muir Woods&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-15.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;More views of Muir Woods&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-9.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Overlooking Stinson Beach&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-13.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Clearer picture of Stinson Beach&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-16.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Overlooking San Rafael&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-17.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sunset view of Battery Spencer&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-22.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Marin Headlands, the descent reaches -18% slope (there’s a sign)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-21.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Ocean Beach, just south of Lands’ End&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-24.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Lake Merced Park&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-26.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Foggy Golden Gate Bridge&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-27.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;View from just past the Seven Sisters&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-31.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Amy’s Island Peak&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-23.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Alcatraz Island&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-28.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;View of a cell at Alcatraz&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-25.jpg&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;San Francisco’s Cable Car Museum&lt;/p&gt;
&lt;/blockquote&gt;</content><summary type="html">Starting off, I’m roughly four months late! I decided to do one of these posts for each internship, and since I’m starting my next co-op in Chicago at Citadel Securities in less than 2 weeks, and I have an exam in 3 days, there’s no better time to procrastinate.</summary></entry><entry><title type="html">Software Engineering Internship: Yelp Inc</title><link href="http://horatiulazu.ca/blog/coop/2018/11/25/yelp.html" rel="alternate" type="text/html" title="Software Engineering Internship: Yelp Inc" /><published>2018-11-25T18:49:29-05:00</published><updated>2018-11-25T18:49:29-05:00</updated><id>http://horatiulazu.ca/blog/coop/2018/11/25/yelp</id><content type="html" xml:base="http://horatiulazu.ca/blog/coop/2018/11/25/yelp.html">&lt;p&gt;&lt;img src=&quot;/blog/assets/yelp-logo-2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Anything I say here is my own words, and does not represent Yelp.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt; Table of contents &lt;/b&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#intro&quot;&gt; Introduction &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#application&quot;&gt; Application Process &lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#application&quot;&gt; Applying&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#interviews&quot;&gt; Interviews &lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#compensation&quot;&gt; Compensation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#projectselection&quot;&gt; Project Selection&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#internevents&quot;&gt; Internship Events &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#office&quot;&gt; 140 New Montgomery Office &lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;intro&quot;&gt; Introduction &lt;/h3&gt;
&lt;p&gt;I did a co-op term at Yelp in Fall 2018 on the Production Engineering team in San Francisco, California. It went great with a lot of learning and an excellent team. Learn more about what I did at Yelp &lt;a href=&quot;/blog/coop/2018/11/24/thirdcoop.html&quot; target=&quot;_blank&quot;&gt; here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;My favourite part was the amazing mentorship and getting to see my project rolled out to production. The experience overall felt “chill”, with the culture being more &lt;em&gt;startup-y&lt;/em&gt;, making room for a unique experience.&lt;/p&gt;

&lt;h3 id=&quot;application&quot;&gt; Applying &lt;/h3&gt;

&lt;p&gt;Since I attend the University of Waterloo, I went through our job board. I submitted my resume and grade report. I was then contacted to do a HackerRank challenge. The position was reasonably competitive, over 500 applicants for around 10-20 spots.&lt;/p&gt;

&lt;h3 id=&quot;interviews&quot;&gt; Interviews &lt;/h3&gt;

&lt;p&gt;The first step is a HackerRank challenge, which was one problem and you had 15 minutes to do it. It’s a very simple problem, mostly used to take out people who would be unlikely to pass the following rounds.&lt;/p&gt;

&lt;p&gt;The second round is a 45 minute Skype call with another engineer, where I had a medium difficulty problem (dynamic programming), and talked about my previous work at Bloomberg.&lt;/p&gt;

&lt;p&gt;The final round is two back-to-back 45 minute calls, including system design and another easy algorithms round along with some networking and operating system trivia.&lt;/p&gt;

&lt;h3 id=&quot;compensation&quot;&gt; Compensation &lt;/h3&gt;

&lt;p&gt;The compensation is ok, comparable to other Bay Area companies (similar to Google, lower than Facebook) but it was my lowest paying term. The issue with the compensation is the lack of corporate housing, since the housing stipend is heavily taxed and less than initially perceived.&lt;/p&gt;

&lt;h3 id=&quot;projectselection&quot;&gt; Project Selection &lt;/h3&gt;

&lt;p&gt;Since the roles are fairly specific (infrastructure, backend, fullstack, etc), you don’t know your team placement until a few weeks before the term begins.&lt;/p&gt;

&lt;p&gt;For me specifically, I had no prior experience with production engineering and received that team placement which in my opinion seemed like a risky maneuver since I hadn’t previously shown any interest in the field.&lt;/p&gt;

&lt;p&gt;However, in the end it turned out fine and got to learn many new topics including general infrastructure, cloud technologies and networking.&lt;/p&gt;

&lt;h3 id=&quot;internevents&quot;&gt; Internship Events &lt;/h3&gt;
&lt;p&gt;We had an impressive amount of events for an off-season internship including (but not limited to):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Exploratorium&lt;/li&gt;
  &lt;li&gt;Bowling&lt;/li&gt;
  &lt;li&gt;Mini-golf putt&lt;/li&gt;
  &lt;li&gt;Escape room&lt;/li&gt;
  &lt;li&gt;Hike + visit to Amy’s Island&lt;/li&gt;
  &lt;li&gt;Magic show&lt;/li&gt;
  &lt;li&gt;Ice skating trip&lt;/li&gt;
  &lt;li&gt;Salsa dancing&lt;/li&gt;
  &lt;li&gt;Pumpkin carving&lt;/li&gt;
  &lt;li&gt;Lunch with executives&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And of course lots of food events!&lt;/p&gt;

&lt;h3 id=&quot;office&quot;&gt;140 New Montgomery Office&lt;/h3&gt;

&lt;p&gt;The office is very cute, and is actually a historic landmark and was formerly one of the tallest in SF!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/yelp-office.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The office was decorated and full of Christmas spirit :)
&lt;img src=&quot;/blog/assets/yelp-office7.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Each floor had a pantry, so over 13 pantries which all look different!
&lt;img src=&quot;/blog/assets/yelp-office6.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/yelp-office5.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/yelp-office2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Another seasonal decoration, but for Halloween …
&lt;img src=&quot;/blog/assets/yelp-office4.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Guess who did this? We had a team event :-)
&lt;img src=&quot;/blog/assets/sf-30.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I worked on Floor 11. Just as a fun fact, Bloomberg actually has their San Francisco Engineering office in the same building as Yelp, they are just several floors above!&lt;/p&gt;</content><summary type="html"></summary></entry><entry><title type="html">Work Term #3: Scalable cloud metadata search</title><link href="http://horatiulazu.ca/blog/coop/2018/11/24/thirdcoop.html" rel="alternate" type="text/html" title="Work Term #3: Scalable cloud metadata search" /><published>2018-11-24T18:49:29-05:00</published><updated>2018-11-24T18:49:29-05:00</updated><id>http://horatiulazu.ca/blog/coop/2018/11/24/thirdcoop</id><content type="html" xml:base="http://horatiulazu.ca/blog/coop/2018/11/24/thirdcoop.html">&lt;p&gt;&lt;img src=&quot;/blog/assets/yelp-logo-2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;During my third co-op, I developed and shipped a scalable cloud metadata search service at Yelp. The core service is written in Python, and I used Terraform and Puppet to provision and configure the infrastructure promoting reproducability and scalability. This is hosted on AWS, more specifically using a serverless architecture leveraging API Gateway and Lambda.&lt;/p&gt;

&lt;p&gt;What is a &lt;em&gt;cloud metadata search service&lt;/em&gt;? Put simply, it keeps an inventory of all the servers that Yelp has and any facts about them. Some examples of facts include software that is provisioned on that machine, operating system information, memory available, geographical regions and hundreds of other fields.&lt;/p&gt;

&lt;p&gt;This service presents the following features:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Expressive discovery using custom DSL querying capabilities in 2 languages (JSON and query string)&lt;/li&gt;
  &lt;li&gt;Significantly faster querying (&amp;lt;100ms per query, real-time event-based invalidation, 5 minute refreshes)&lt;/li&gt;
  &lt;li&gt;Highly scalable serverless architecture which is reproducable and configured using code&lt;/li&gt;
  &lt;li&gt;Deployment process using S3 and Jenkins, unit tests and end-to-end tests using Docker&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My favourite part of this project is that I went through all stages of the development process, and got to see something created from scratch go through to production!&lt;/p&gt;

&lt;p&gt;Formerly, there was a solution using MCollective that would distribute the request to all known hosts and fetch information then. The issue with that solution is that the query time is essentially a function of the slowest host to respond - since it would wait for all hosts to respond and filter afterwards.&lt;/p&gt;

&lt;p&gt;Meanwhile, the inventory service works in the other direction. Instead, each host contains a cron-job that emits metadata on that machine to the inventory service.&lt;/p&gt;

&lt;p&gt;The service has its own DSL query language, which can be provided in JSON:&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;filter&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;AND&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;args&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
             &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;matching&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
             &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;arg&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;hostname: interndev1-us[east,west]1dev*&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
             &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;matching&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
             &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;arg&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cpu_count &amp;gt;= 16&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;sort&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;uptime asc, hostname desc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;limit&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;offset&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;index_epoch_threshold&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Alternatively using the string query syntax (inspired by Apache Solr’s streaming syntax):&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ search(filter(AND(&quot;hostname: interndev1-us[east,west]1dev*&quot;, &quot;cpu_count &amp;gt;= 16&quot;)), sort(&quot;uptime asc, hostname desc&quot;), limit(1000), offset(10), index_epoch_threshold(2000))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;As part of this project, I also implemented query parsers for both that convert the associated query into an Elasticsearch URI query. This included making some interesting optimizations along with a basic n-ary preorder tree traversal to assemble the query string.&lt;/p&gt;

&lt;p&gt;One of the greatest challenges was dealing with a schemaless design. Since there’s hundreds of fields, it isn’t managable to manually introduce every field in a fixed schema since teams are constantly adding or removing fields. Luckily, Elasticsearch provides the ability to give a &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html&quot;&gt;dynamic schema&lt;/a&gt;, where it infers type. However, this was quickly proven unreliable because we experienced type collisions (ex: initially a field was &lt;code class=&quot;highlighter-rouge&quot;&gt;bool&lt;/code&gt;, later it would be indexed as &lt;code class=&quot;highlighter-rouge&quot;&gt;int&lt;/code&gt;). Such a type collision would yield errors when ingesting metadata - later invalidating that instance from search results and returning incomplete data!&lt;/p&gt;

&lt;p&gt;The solution to this was leveraging a &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-templates.html&quot;&gt;dynamic templated mapping&lt;/a&gt;. We would have four types: &lt;code class=&quot;highlighter-rouge&quot;&gt;*_str&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;*_bool&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;*_long&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;*_float&lt;/code&gt;. The service would append to each field being ingested the type it thinks would be the type. This type would always conform with the equivalent Elasticsearch type, hence all ingestion requests would go through. The only concern now becomes - fields can sometimes be more sparse and scattered across multiple fields - at worst 4x worse performance! However, this rarely the case, and providing the guaranteed that documents will be ingested is more critical than &lt;em&gt;slightly&lt;/em&gt; slower retrieval.&lt;/p&gt;

&lt;p&gt;How does this work for retrievals? All the retrieval queries would need to be appropriately tokenized, have type introspection occur and inspect the mapping of the index, and then adjusted accordingly. This includes expanding any numerical field queries to be &lt;code class=&quot;highlighter-rouge&quot;&gt;(field_long:val OR field_float:val)&lt;/code&gt;. While a tricky process for all the arguments that can be passed to the inventory service, the strict DSL and with a careful implementation and lots of unit tests it worked well.&lt;/p&gt;

&lt;p&gt;The final benchmarks using Apache Bench and AWS CloudWatch yield &amp;lt;150ms p99 query times for indexing and &amp;lt;90ms p99 search queries while exceeding one million API requests daily.&lt;/p&gt;

&lt;p&gt;To conclude, I learned a lot this term with an amazing mentor who was extremely helpful throughout the entire process - something which I think is invaluable and definitely made this one of my favourite terms.&lt;/p&gt;</content><summary type="html"></summary></entry><entry><title type="html">YouTube: Analytics on 1.2 million views</title><link href="http://horatiulazu.ca/blog/programming/2018/11/12/youtube.html" rel="alternate" type="text/html" title="YouTube: Analytics on 1.2 million views" /><published>2018-11-12T18:49:29-05:00</published><updated>2018-11-12T18:49:29-05:00</updated><id>http://horatiulazu.ca/blog/programming/2018/11/12/youtube</id><content type="html" xml:base="http://horatiulazu.ca/blog/programming/2018/11/12/youtube.html">&lt;p&gt;&lt;img src=&quot;/blog/assets/youtube-cover.png&quot; alt=&quot;link&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I’ve been running my YouTube channel &lt;a href=&quot;https://www.youtube.com/user/ComputerBunnyMath123&quot; target=&quot;_blank&quot;&gt;SoftwareEngenius&lt;/a&gt; for the past six years. Initially, it started as a place to post videos regarding my hobbies (mostly computer tutorials and programming videos). It has mostly stayed that way, with more recent videos being very focused on software development.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Sometimes it may count under 1.2 million -  it’s either statisics not updated or unlisted videos.&lt;/p&gt;

&lt;h4&gt; Motivation&lt;/h4&gt;
&lt;p&gt;I had a fantastic experience building out my YouTube channel, and I don’t regret the many hours spent on this channel. The following, however, is worth noting:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The goal of the channel isn’t about “becoming popular” or “getting rich”, rather it was more for me to genuinely produce content that I thought had some value. Unfortunately, this also means I don’t have much interest in production quality, and felt like getting my thoughts out are more important than spending time editing.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I believe I was successful in reaching my goal. I was able to make a clear amount of videos covering a wide span of topics, though it clearly shows as some of my videos aren’t of the best quality. From 2013-2015 I gained momentum and my channel was growing, and to keep that going I was heavily invested in producing more quantity, which at the time led to saturation in my video content.&lt;/p&gt;

&lt;h4&gt; Beginning: 2012/2013&lt;/h4&gt;
&lt;p&gt;This was the starting phase of the channel, back when it was called &lt;code class=&quot;highlighter-rouge&quot;&gt;ComputerBunnyMath123&lt;/code&gt;. Clearly, I didn’t have any niche in mind, so I began by posting completely random videos including programming tutorials, software videos and some games including Minecraft, Chess and Brain Age 2. I didn’t get many views at the start, only after adding more content (~20 videos) did I start getting over 1,000 views per month.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/youtube-growth.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4&gt; Growing Content and Saturation: 2013/2014/2015&lt;/h4&gt;
&lt;p&gt;This period I would characterize as gaining many more views, which led me to wanting more and produce vasts amounts of videos. It was mostly sparked by my &lt;a href=&quot;https://www.youtube.com/watch?v=MEvY27PB6ZU&quot; target=&quot;_blank&quot;&gt;Ripley’s Aquarium video&lt;/a&gt;, which got over 20,000 views early on and motivated me to continue producing random content. This continued for some time, and I spent most of the Summer of 2014 reaching out to companies to review their products.&lt;/p&gt;

&lt;p&gt;I wouldn’t say this period of time was used effectively - I ended up greatly saturating my channel with a wide array of random topics which led to very poor user retention.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/youtube-growing.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4&gt; Focused and Slowing Growth: 2016/2017&lt;/h4&gt;

&lt;p&gt;During this time period I didn’t have a lot of time to devote to making videos (I was busy applying to university or in my freshmen year), so I had to focus my efforts. By this time, I gained some exposure to various Computer Science concepts more in-depth, and made the decision to change the focus of the channel to be &lt;em&gt;only software related&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/youtube-maturing.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4&gt; Matured and Rarely Updated: 2017 onwards&lt;/h4&gt;
&lt;p&gt;I hadn’t uploaded many videos recently, occasionally only when I visit an interesting concept or learn something more niche I would bother to make a new video. I don’t actively pursuit creating videos for the views or fame. Instead, if I find something cool I’ll share it! Some notable videos during this time period includes my functional programming channel or an &lt;em&gt;upcoming series I am working on&lt;/em&gt;!&lt;/p&gt;

&lt;p&gt;More interestingly though, is despite the lack of posting videos I didn’t drop much at all in terms of revenue or views. Personally, I find this surprising because many of my videos tags included &lt;code class=&quot;highlighter-rouge&quot;&gt;2014&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;2015&lt;/code&gt;, but seems despite this I’m still getting traffic.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/youtube-current.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4&gt; Future Plans&lt;/h4&gt;

&lt;p&gt;I have no plans for this channel. If I find something cool - I will make a video and post it :)&lt;/p&gt;

&lt;h4&gt; More Analytics!&lt;/h4&gt;

&lt;p&gt;Who doesn’t enjoy numbers and charts? Below are standard analytics provided by YouTube.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/youtube-views.png&quot; alt=&quot;link&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, my most popular videos aren’t representative at all of my channel as a whole - but this goes to show how luck with tags and spotting a niche can help bring in more viewers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/youtube-device.png&quot; alt=&quot;link&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I find it interesting how the time spent on mobile is almost as much as on the computer - and that such a large proportion of viewers watch on phone or tablet.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/youtube-traffic.png&quot; alt=&quot;link&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Interestingly, it looks like YouTube’s recommender systems worked in my favour from August 2014 to February 2015 and then rarely suggested my videos until late 2016….&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/youtube-age.png&quot; alt=&quot;link&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are no surprises here, the vast majority of viewers will be “tech savvy” and likely near college age.&lt;/p&gt;

&lt;p&gt;All in all, hope you enjoyed these facts and numbers :)&lt;/p&gt;

&lt;!-- ![link](/blog/assets/youtube-os.png)

Interestingly, there were more Macintosh users than Windows until around late 2015. This is likely because I used to have more content for Mac users. More interestingly, is that Mac and iOS users tend to watch my videos for longer!


![link](/blog/assets/youtube-functional.png)
--&gt;</content><summary type="html"></summary></entry><entry><title type="html">Evolution of stravawindanalysis.com</title><link href="http://horatiulazu.ca/blog/programming/2018/11/09/strava.html" rel="alternate" type="text/html" title="Evolution of stravawindanalysis.com" /><published>2018-11-09T18:49:29-05:00</published><updated>2018-11-09T18:49:29-05:00</updated><id>http://horatiulazu.ca/blog/programming/2018/11/09/strava</id><content type="html" xml:base="http://horatiulazu.ca/blog/programming/2018/11/09/strava.html">&lt;style type=&quot;text/css&quot;&gt;
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
&lt;/style&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry
    }
});
MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/stravawindanalysis-logo.png&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt; Table of contents &lt;/b&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#intro&quot;&gt; Motivation and Introduction &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#redesign&quot;&gt; Extensive Redesign &lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#features&quot;&gt; Features&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#architecture&quot;&gt; Architectural overview &lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#models&quot;&gt; Models and algorithms&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#infrastructure&quot;&gt; Site infrastructure&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#youtube&quot;&gt; YouTube demo&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#original&quot;&gt; Original Design &lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#origarchitecture&quot;&gt; Architectural overview &lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#origyoutube&quot;&gt; YouTube demo &lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#future&quot;&gt; Future Plans &lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#global&quot;&gt; Global neural network models &lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;intro&quot;&gt; Motivation and Introduction &lt;/h3&gt;

&lt;p&gt;During high-school I was wondering if there was some way to determine how much wind affects road cyclists’ speeds.&lt;/p&gt;

&lt;p&gt;Strava is a popular cycling platform, where riders “record” their rides and share with others. This is accomplished by using GPS that periodically captures longitutde/latitude and timestamps it in GPX format - so at any given moment Strava can recollect your position and calculate your speed. Segments are defined roughly as a string following a polyline starting from one coordinate and ending at another coordinate with a predefined shape. Over time, many people upload their rides and we can get a leaderboard of different people’s attempts at segments over time.&lt;/p&gt;

&lt;p&gt;The critical issue with this segment functionality is that conditions aren’t always equal - if you have a 50km/h tailwind you will go have to displace less wattage to reach that winning speed - but how much does it really help you? Introducing Strava Wind Analysis!&lt;/p&gt;

&lt;h2 id=&quot;redesign&quot;&gt; Extensive Redesign &lt;/h2&gt;
&lt;p&gt;The most apparent issue with the initial design is the absence of a backend which severely limits the capabilities of the web app since everything resides client-sided. The newer design features a cloud-hosted architecture stored on Amazon Web Services, opening a world of possibilities.&lt;/p&gt;

&lt;h3 id=&quot;features&quot;&gt; Features &lt;/h3&gt;
&lt;p&gt;The newer version of the website expands beyond simply weather analytics to providing both historical and segment ride analytics. There are feature additions throughout, including:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Improved regression models for cycling wind impact determination&lt;/li&gt;
  &lt;li&gt;Content-based segment recommendation engine for scrolling feed&lt;/li&gt;
  &lt;li&gt;Interactive charts using chart.js&lt;/li&gt;
  &lt;li&gt;Performance analytics on historical segment and aggregate data&lt;/li&gt;
  &lt;li&gt;Individual modals with athlete-specific statistics on segment leaderboard&lt;/li&gt;
  &lt;li&gt;Linear regression and interpolation tools using scikit-learn&lt;/li&gt;
  &lt;li&gt;Segment and ride filtering options (distance, speed, etc.)&lt;/li&gt;
  &lt;li&gt;Improved performance with Redis caching&lt;/li&gt;
  &lt;li&gt;Integration with MongoDB including weather API throttling and user profiles&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After users login, they are presented with the feed page. Powered by a content-based recommender system, this feed aims at featuring segments that are recent and may be of interest.&lt;/p&gt;

&lt;p&gt;The new details page is redesigned, with tabs for different content for that segment.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/strava-details.png&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are modals now for individual athletes showing historical performance aggregate performance on segments. Similarily, there are modals on the ride selection screen showing a map of the ride.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/strava-modal.png&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The charting system allows the ability to do speed overlay for different athletes on a single chart.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/strava-comparison.png&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;architecture&quot;&gt; Architectural overview &lt;/h3&gt;
&lt;p&gt;The newer architecture runs on Amazon Web Services using EC2 instances and Route53 for Elastic IPs. The infrastructure is managed using Terraform, which allows for reproducability and high scalability.&lt;/p&gt;

&lt;p&gt;The core site is a monolithic repository written in Node.js leveraging Express to power the webserver layer, along with Handlebars as the templating engine for rendering the site headers and footers. The front-end leverages jQuery and Ink Framework. There is a seperate Python Flask service handling the machine learning components, which uses NumPy and Scikit-Learn for any statistical analysis and is communicated using a RESTful interface by the Node app. Both the Node and Python server are managed by PM2, which allows for thread forking and zero downtime restarts.&lt;/p&gt;

&lt;p&gt;Redis is used as an in-memory cache for API look-ups (30 minutes TTL), and provides lifetime caching for weather data requests from DarkSky. Elasticsearch provides an index for segment and rides by rides, which periodically indexes upon login based on a previously set epoch-update time. Lastly, MongoDB is used for user profiles including throttling for abusive users.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/strava-system.png&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;models&quot;&gt; Models and Algorithms &lt;/h3&gt;

&lt;h4&gt; Wind Impact Determination Algorithm &lt;/h4&gt;
&lt;p&gt;The core intent of the Strava Wind Analysis site is to numerically quantify the impact of wind conditions on a cycling segment. Since this isn’t a solved problem and there is no method to verify the validity of the results, over time the algorithm evolved to take into consideration more factors which increases the likelyhood of accuracy.&lt;/p&gt;

&lt;p&gt;The original algorithm used basic theory from relative physics, that is, we take two vectors representing the wind direction and ride direction, add then tip-to-tail, and then take the displacement vector which would be the resultant vector. The impact would be the delta between the original ride vector and the displacement.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/strava-relative.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The beginning set of improvements over the legacy vector-manipulation approach concerns drawing conclusions from the results of an empirical study on how wind affects cyclists. The following results are taken from Jobst Brandt’s &lt;em&gt;A Practical Analysis of Aerodynamic Drag&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The first observation is that the previous vector-based model falls victim to assuming that tailwind and headwind will equivalently affect riders which is incorrect.
&lt;img src=&quot;/blog/assets/strava-normalized.png&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The second observation is to provide a mapping for how much a difference in speed makes for the wind impact. This is of course very difficult, but can be best modelled using a function. What is this function?&lt;/p&gt;

&lt;p&gt;$f(x) = -0.004x^2 + 0.616x + 0.863$&lt;/p&gt;

&lt;p&gt;How was this equation generated? Using quadratic regression on empirical riding data in a wind tunnel (assuming that the head-wind is direct), and with a constant wattage it’s possible to interpolate values.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/strava-wind-graph.png&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Thus, $x$ is the wind-speed in direct head-wind, and $y$ would be the net change in wind-speed. Since wind isn’t always directed parallel to the cyclist, the former vector manipulation algorithm is executed but both units are turned into unit vectors, and then the displacement vector’s magnitude is multiplied by the value of this function yielding the final result.&lt;/p&gt;

&lt;p&gt;This works fairly well in practice, however there is more to consider. There is a plethora of data containing historical wind performance and the speed at which the cyclist rode. Ignoring factors (amount of effort or energy the rider places), it’s possible to use non-anomalous efforts as training data for a statistical model.&lt;/p&gt;

&lt;p&gt;Former segment efforts can be used as training data. Consider a function $H(x, y, z)$ where $x$ is the effort distance, $y$ is the effort slope, and $z$ is the direction-adjusted wind speed (see the former vector approach), and returns the expected segment effort speed. Clearly, every segment effort has values for $x$, $y$ and $z$ hence this becomes a classic application of regression and/or neural networks. At the end, calling the same function with $z=0$ will predict the speed without the influence of wind - hence $H(x, y, z) - H(x, y, 0)$ is the impact!&lt;/p&gt;

&lt;p&gt;First attempt used multivariate linear regression with several features including effort distance, moving time, ride bearing, average speed for the whole ride, wind speed and wind bearing. After normalizing the values with a standard scalar, applying the vector manipulation approach, and using a 70%/15%/15% training/cross-validation/test split, below are some sample results:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sample predicted vs actual
---
25.26km/h vs 29.28km/h
26.02km/h vs 28.65km/h
26.57km/h vs 28.04km/h
22.04km/h vs 22.6km/h
22.11km/h vs 21.74km/h
18.63km/h vs 19.85km/h
27.04km/h vs 29.26km/h
21.28km/h vs 23.02km/h
26.2km/h vs 27.28km/h
20.6km/h vs 22.46km/h
26.34km/h vs 29.62km/h
26.01km/h vs 27.42km/h
29.27km/h vs 29.55km/h
27.41km/h vs 29.61km/h
---
Root Mean Squared Error: 6.1968908459
Coefficients:  [-0.31109429 -0.49802149 -3.11181539]
Intercept:  25.9555685519
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;While the results are accurate on the most part, some results greatly increase the RMSE:&lt;/p&gt;

&lt;p&gt;$RMSE(y)=\frac{1}{N}\sqrt{\sum_i{(f(x_i) - y_i)^2}}$&lt;/p&gt;

&lt;p&gt;During actual segment efforts, this model is significant off inflating the expected result since most efforts during KOM attempts &lt;em&gt;are&lt;/em&gt; anomalous themselves! Hence, this model will be wrong, but that is OK since only $z$ is changing.&lt;/p&gt;

&lt;p&gt;The other approach is using neural networks. Using a multilayered perceptron neural network, a similar process was used as the multivariate linear regression model in terms of features and approach. While it certainly sounds fancy, using the Scikit-Learn library it makes it relatively straightforward to apply.&lt;/p&gt;

&lt;p&gt;The final results after doing some hyperparameter tuning (using the Stochastic Gradient Descent model):&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sample predicted vs actual
---
24.75km/h vs 22.36km/h
25.5km/h vs 32.15km/h
25.29km/h vs 18.81km/h
24.6km/h vs 28.44km/h
25.12km/h vs 29.28km/h
25.99km/h vs 28.65km/h
26.61km/h vs 28.04km/h
21.36km/h vs 22.6km/h
21.43km/h vs 21.74km/h
17.36km/h vs 19.85km/h
27.18km/h vs 29.26km/h
20.47km/h vs 23.02km/h
26.2km/h vs 27.28km/h
19.66km/h vs 22.46km/h
26.36km/h vs 29.62km/h
25.99km/h vs 27.42km/h
29.75km/h vs 29.55km/h
27.6km/h vs 29.61km/h
Root Mean Squared Error: 5.60815702584
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;While the root mean squared error is lower, this model performs better with the anomalous cases but poorer on median. With both models into consideration, the multivariate linear regression model remains the top choice as the core system for computing wind impact.&lt;/p&gt;

&lt;h4&gt; Infinite Scrolling Segment Feed Recommendation Algorithm &lt;/h4&gt;
&lt;p&gt;The motivator of the content-based feed from a product perspective is to provide:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Very fast way of showing relevant segments to the user (instead of searching for them)&lt;/li&gt;
  &lt;li&gt;Allow the user to discover potentially unique or anomalous segments&lt;/li&gt;
  &lt;li&gt;Provide an incentive for returning to the site by outlining fresh new content&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The most stressed factor is &lt;em&gt;new&lt;/em&gt; content, hence the recommender system heavily boosts more recent rides. As such, below are some factors taken into consideration when ranking segments:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;How recent was the ride that the segment took place on?&lt;/li&gt;
  &lt;li&gt;Has there been a KOM/QOM achieved?&lt;/li&gt;
  &lt;li&gt;Is there a new Personal Best or Top 10 rank achieved?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Another criteria for this recommender system is that it must be quick to retrieve results - since this is the first thing the user lands on once logging in. The rough algorithm looks as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Lazily fetch ride data from Strava API in sets of 3 rides
    &lt;ul&gt;
      &lt;li&gt;Redis will cache the newer than &lt;code class=&quot;highlighter-rouge&quot;&gt;index-epoch&lt;/code&gt; rides faster than Elasticsearch indices&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Iterate through all segments from those rides and rank candidates
    &lt;ul&gt;
      &lt;li&gt;This will use the points system below&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If there are less than &lt;code class=&quot;highlighter-rouge&quot;&gt;16&lt;/code&gt; segments retrieved, lazily load more until failure&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;How are segments ranked? This is computed as follows:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Factor&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Formula&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Factor Type&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Ride Recency&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;10x, 5x or 1x&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Multiplier&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;KOM/QOM Achievement&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;20&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Addition&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Leaderboard Ranking&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;20 - rank&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Addition&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Personal Best&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;5 - rank&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Addition&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;
This systematic scoring system provides a heuristic for rankings segments. In recommender system theory, this qualifies as a content-based recommender system since we rank content based solely on discrete characteristics.&lt;/p&gt;

&lt;h3 id=&quot;youtube&quot;&gt; YouTube Demo &lt;/h3&gt;

&lt;iframe width=&quot;740&quot; height=&quot;430&quot; src=&quot;https://www.youtube.com/embed/3eSN6_m8yao&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h2&gt;&lt;br /&gt;&lt;/h2&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;original&quot;&gt; Original Design &lt;/h2&gt;
&lt;p&gt;For my first web-app ever, I created a single page web-app in high-school using client sided jQuery and JavaScript along with a simple vector manipulation algorithm. This design features both critical design flaws and is extremely limiting in terms of capabilities.&lt;/p&gt;

&lt;h3 id=&quot;origarchitecture&quot;&gt; Architectural Overview &lt;/h3&gt;
&lt;p&gt;As mention prior, everything is stored client-sided, so there is no session data persisted. The website design is created using Materialize CSS and jQuery. The core logic is written in JavaScript, which can actually be found at &lt;code class=&quot;highlighter-rouge&quot;&gt;src/js&lt;/code&gt;. The site interacts with the Strava API using OAuth, Google Maps API and Dark Sky API to fetch the weather data. The site can be found at &lt;code class=&quot;highlighter-rouge&quot;&gt;stravawindanalysis.com/legacy&lt;/code&gt;, with the exception of API keys which were stubbed with API calls to the newer backend.&lt;/p&gt;

&lt;p&gt;The simple algorithm worked by fetching the wind data, the ride direction, normalizing the vectors, scaling the vectors by their respective speeds, and then checking the displacement when added tip-to-tail.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/stravawindanalysis-legacy.png&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;origyoutube&quot;&gt; Original Design YouTube Demo &lt;/h3&gt;

&lt;iframe width=&quot;740&quot; height=&quot;430&quot; src=&quot;https://www.youtube.com/embed/v57Ok0zRMNI&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;future&quot;&gt; Future Plans &lt;/h2&gt;
&lt;h3 id=&quot;global&quot;&gt; Global Neural Networks &lt;/h3&gt;

&lt;p&gt;Extending from the idea of the current models, adding the ability to expand the training set to use information from other riders can allow for significantly more advanced capabilities. Additional features will be created dependent on the rider, for example the rider’s average speed, riding patterns, and then every user’s behavior can be contributed to a global state neural network.&lt;/p&gt;

&lt;p&gt;Of course, users can subscribe/unsubscribe from donating their personal data - but these capabilites will allow for pooling more data and attempting to create a more accurate model for estimating speed given the ride environment and player type.&lt;/p&gt;</content><summary type="html"></summary></entry><entry><title type="html">Postmortem: Tenderloin + Yet another stolen road bike</title><link href="http://horatiulazu.ca/blog/cycling/2018/11/04/bike-stolen.html" rel="alternate" type="text/html" title="Postmortem: Tenderloin + Yet another stolen road bike" /><published>2018-11-04T18:49:29-05:00</published><updated>2018-11-04T18:49:29-05:00</updated><id>http://horatiulazu.ca/blog/cycling/2018/11/04/bike-stolen</id><content type="html" xml:base="http://horatiulazu.ca/blog/cycling/2018/11/04/bike-stolen.html">&lt;p&gt;On Saturday November 3, 2018 I decided to spend the day going on a warmup 65km ride down to Mountain View from San Francisco, meet up with a couple friends, then come back by Caltrain as preparation for a hard Sunday ride going up King’s Mountain.&lt;/p&gt;

&lt;p&gt;On the return trip, the Caltrain was closed for repairs, so I had to take a bus from San Bruno to San Francisco. I tried to put my bike inside the bus, but the driver refused stating that it’s against their policy - so I put it on the rack outside. Looking out the window into darkness, the bus drove comfortably on the highway until getting to Market and 6th avenue.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/sf-mta-rack.jpg&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There was a red light at Market and 6th avenue, and out of the corner appears one person who rushes to the front of the bus, and before I could blink snatches the bike off the rack. I saw it unfold entirely with my own eyes, but by the time I could react it was too late.&lt;/p&gt;

&lt;p&gt;The bus driver opened the door and I took a run for it, chasing the thief. I had my cycling shoes on, which if you aren’t aware allow me to clip my feet into my pedals. Of course, the disadvantage is that you can’t run in them - in fact even walking on pavement is difficult.&lt;/p&gt;

&lt;p&gt;To make matters worse, it wasn’t just me and that guy who snatched the bike - he had a couple friends joining the party as well. They actually followed me on other road bikes, and warned me to not even try running after him. Eventually I lost sight, and getting into a physical fight with several other guys on me wouldn’t be wise. The bus driver already called 911 and the police arrived.&lt;/p&gt;

&lt;h3 id=&quot;what-went-well&quot;&gt;What went well&lt;/h3&gt;

&lt;p&gt;Looking at the bright side first, there’s a couple things that went well.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;I didn’t have my wallet in my saddle bag (which could have been stolen in the process)&lt;/li&gt;
  &lt;li&gt;Did not get mugged in the process (so phone/wallet were ok)&lt;/li&gt;
  &lt;li&gt;No injuries occured&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As well, my initial instinct was to chase them. But if I did catch up to them - what would I gain?&lt;/p&gt;

&lt;p&gt;I may have knocked the guy off the bike, and taken off:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;I would need to clip-in my pedals fast enough + accelerate so he can’t chase me
    &lt;ul&gt;
      &lt;li&gt;I could hold ~55km/h for 60 seconds to get far enough from him&lt;/li&gt;
      &lt;li&gt;Crashing into people, cars or red lights are of concern to maintain that speed&lt;/li&gt;
      &lt;li&gt;The benefit is that I would keep my bike&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Success rate of clipping in on for both feet is ~15%, high failure rate&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If I failed to clip-in:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Extremely dangerous since I’d be in direct harm of the thief&lt;/li&gt;
  &lt;li&gt;Partial clip-in means that I’m basically bolted to the bike&lt;/li&gt;
  &lt;li&gt;It wasn’t just one person but at least one other
    &lt;ul&gt;
      &lt;li&gt;2 vs 1 and they likely have knives (which I’ve seen many people carry around)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is a picture of sidewalk the thief rode on (though it happened at night):
&lt;img src=&quot;/blog/assets/sf-market-six.jpg&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;what-didnt-go-well&quot;&gt;What didn’t go well&lt;/h3&gt;

&lt;p&gt;I should have made sure my bike never leaves my hands. The issue with this is that you actually can’t lock the bike on the buses. I also explicitely asked to have the bike in the bus, but the driver refused.&lt;/p&gt;

&lt;p&gt;Lastly, I also didn’t have the serial number with me. When the police was there on the scene, it would have been very valuable to have the serial number with me.&lt;/p&gt;

&lt;h3 id=&quot;what-i-did-after-it-got-stolen&quot;&gt;What I did after it got stolen&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;The bus driver called 911 and I did as well after my failed chase - and the cops arrived on the scene&lt;/li&gt;
  &lt;li&gt;I showed bike pictures and described the thief - and they alerted nearby cops to be aware of the event
    &lt;ul&gt;
      &lt;li&gt;Interestingly, I overheard the radios police actually describing bikes being ridden in the area&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;After getting home, I retrieved the serial number and reported the incident online to the police&lt;/li&gt;
  &lt;li&gt;I religiously checked Kijiji, eBay and other websites for the bike or its respective components&lt;/li&gt;
  &lt;li&gt;Posted on Facebook groups making other people aware of the theft&lt;/li&gt;
  &lt;li&gt;Looked into renter’s insurance to see if I could make a claim&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;good-news&quot;&gt;Good news&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Update (November 13, 2018)&lt;/strong&gt;: My renter’s insurance happened to cover the entire road bike - so I got all my road bike’s value back and will be buying another one :)&lt;/p&gt;</content><summary type="html">On Saturday November 3, 2018 I decided to spend the day going on a warmup 65km ride down to Mountain View from San Francisco, meet up with a couple friends, then come back by Caltrain as preparation for a hard Sunday ride going up King’s Mountain.</summary></entry><entry><title type="html">Mount Tamalpais West Summit + Seven Sisters Climb</title><link href="http://horatiulazu.ca/blog/cycling/2018/10/28/mt-tam.html" rel="alternate" type="text/html" title="Mount Tamalpais West Summit + Seven Sisters Climb" /><published>2018-10-28T19:49:29-04:00</published><updated>2018-10-28T19:49:29-04:00</updated><id>http://horatiulazu.ca/blog/cycling/2018/10/28/mt-tam</id><content type="html" xml:base="http://horatiulazu.ca/blog/cycling/2018/10/28/mt-tam.html">&lt;p&gt;In my eyes, the ability to, within 20 minutes of riding, be immersed with stunning views, nature and elevation is the single best perk of being in San Francisco. You cannot find anything like it near Waterloo or Toronto, and it feels like you in picturesque scene in a movie!&lt;/p&gt;

&lt;h3 id=&quot;gameplan&quot;&gt;Gameplan&lt;/h3&gt;
&lt;p&gt;I had no prior experience climbing for extended periods of time. Depending on the derivative you choose, the route can vary widely in distance and elevation.&lt;/p&gt;

&lt;p&gt;I chose one of the more difficult routes - which is doing the Alpine Dam, Seven Sisters and then the West Summit yielding 100km (62 miles) distance and 1500m (5000 feet) elevation gain.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/mount-tam-map.png&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ride-dynamics&quot;&gt;Ride Dynamics&lt;/h3&gt;
&lt;p&gt;Waking up at 6:30am, I ate a full breakfast and set straight to riding. The beginning started off rough, with one of my friends actually crashing while crossing the Golden Gate Bridge due to extreme fog. Luckily he wasn’t badly hurt, and the fog cleared once we passed the bridge. Riding through Sausalito was a pleasure, and we eventually stopped at Fairfax before the climb to eat lunch.&lt;/p&gt;

&lt;p&gt;The climbs started off challenging, at ~6% grade for around 20 minutes. We met up with two other locals, and we tried to hold on while climbing. After, the seven sisters (which is a series of seven descents and climbs) were grueling, since you pickup speed but that final stretch is extremely steep and tough. In fact, after doing the fourth sister I had to stop for a 1 minute break. Lastly, the final stretch was the west summit which was around 300 feet of elevation gain - but that made the view well worth it!&lt;/p&gt;

&lt;p&gt;Descending was actually quite technical, reaching speeds of over 60km/h down the windy roads down a mountain for over 20 minutes will get your adrenaline rush going!&lt;/p&gt;

&lt;h3 id=&quot;west-peak-view&quot;&gt;West Peak View&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/mount-tam.jpg&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;beach-view&quot;&gt;Beach View&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/mount-tam-west-bay.jpg&quot; alt=&quot;I'm an inline-style link&quot; /&gt;&lt;/p&gt;</content><summary type="html">In my eyes, the ability to, within 20 minutes of riding, be immersed with stunning views, nature and elevation is the single best perk of being in San Francisco. You cannot find anything like it near Waterloo or Toronto, and it feels like you in picturesque scene in a movie!</summary></entry></feed>
